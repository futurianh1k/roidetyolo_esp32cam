/**
 * MQTT ëª¨ë“ˆ
 *
 * MQTT ë©”ì‹œì§€ ì²˜ë¦¬ ë° ë°œí–‰
 * ASR (ìŒì„±ì¸ì‹) ëª¨ë“œ ì§€ì› ì¶”ê°€
 */

#include "mqtt_module.h"
#include "audio_module.h"
#include "camera_module.h"
#include "camera_module.h" // cameraSetSink, cameraClearSink
#include "config.h"
#include "display_module.h"
#include "websocket_module.h"
#include <Arduino.h>
#include <ArduinoJson.h>
#include <PubSubClient.h>


// ì™¸ë¶€ ë³€ìˆ˜
extern bool cameraActive;
extern bool microphoneActive;

/**
 * MQTT ë©”ì‹œì§€ ìˆ˜ì‹  ì½œë°±
 */
void mqttCallback(char *topic, byte *payload, unsigned int length) {
  DEBUG_PRINTF("MQTT message received: %s\n", topic);

  // JSON íŒŒì‹± (ASR ëª…ë ¹ì„ ìœ„í•´ ë” í° ë²„í¼ ì‚¬ìš©)
  StaticJsonDocument<1024> doc;
  DeserializationError error = deserializeJson(doc, payload, length);

  if (error) {
    DEBUG_PRINTF("JSON parsing failed: %s\n", error.c_str());
    return;
  }

  // ëª…ë ¹ ì¶”ì¶œ
  const char *command = doc["command"];
  const char *action = doc["action"];
  const char *requestId = doc["request_id"];

  DEBUG_PRINTF("Command: %s, Action: %s\n", command, action);

  // í† í”½ë³„ ì²˜ë¦¬
  String topicStr = String(topic);

  if (topicStr.endsWith("/camera")) {
    // âœ¨ ì˜ìƒ sink ê´€ë ¨ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    const char *sinkUrl = doc["sink_url"] | nullptr;
    const char *streamMode = doc["stream_mode"] | nullptr;
    int frameInterval = doc["frame_interval"] | 1000;

    handleCameraControl(action, requestId, sinkUrl, streamMode, frameInterval);
  } else if (topicStr.endsWith("/microphone")) {
    // âœ¨ ASR ê´€ë ¨ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ìˆì„ ìˆ˜ë„ ìˆê³  ì—†ì„ ìˆ˜ë„ ìˆìŒ)
    const char *sessionId = doc["session_id"] | nullptr;
    const char *wsUrl = doc["ws_url"] | nullptr;

    handleMicrophoneControl(action, requestId, sessionId, wsUrl);
  } else if (topicStr.endsWith("/speaker")) {
    const char *audioUrl = doc["audio_url"];
    int volume = doc["volume"] | 70; // ê¸°ë³¸ê°’ 70%

    // ë³¼ë¥¨ ì„¤ì •
    if (volume >= 0 && volume <= 100) {
      audioSetVolume((uint8_t)volume);
    }

    handleSpeakerControl(action, audioUrl, requestId);
  } else if (topicStr.endsWith("/display")) {
    const char *content = doc["content"];
    const char *emojiId = doc["emoji_id"];
    handleDisplayControl(action, content, emojiId, requestId);
  } else if (topicStr.endsWith("/system")) {
    handleSystemControl(action, requestId);
  }
}

/**
 * ì¹´ë©”ë¼ ì œì–´ ì²˜ë¦¬ (ì˜ìƒ sink ì „ì†¡ í¬í•¨)
 *
 * @param action ì•¡ì…˜ (start, pause, stop)
 * @param requestId ìš”ì²­ ID
 * @param sinkUrl ì˜ìƒ sink ì£¼ì†Œ (startì¼ ë•Œë§Œ ì‚¬ìš©)
 * @param streamMode ì „ì†¡ ë°©ì‹ (startì¼ ë•Œë§Œ ì‚¬ìš©)
 * @param frameInterval í”„ë ˆì„ ê°„ê²© (ms, startì¼ ë•Œë§Œ ì‚¬ìš©)
 */
void handleCameraControl(const char *action, const char *requestId,
                         const char *sinkUrl, const char *streamMode,
                         int frameInterval) {
  bool success = false;
  String message = "";

  if (strcmp(action, "start") == 0) {
    // âœ¨ ì˜ìƒ sink ì„¤ì • (ìˆì„ ê²½ìš°)
    if (sinkUrl && streamMode) {
      DEBUG_PRINTLN("ğŸ“¹ ì˜ìƒ sink ì„¤ì • ìˆ˜ì‹ ");
      DEBUG_PRINTF("   URL: %s\n", sinkUrl);
      DEBUG_PRINTF("   ëª¨ë“œ: %s\n", streamMode);
      DEBUG_PRINTF("   ì£¼ê¸°: %d ms\n", frameInterval);

      cameraSetSink(sinkUrl, streamMode, frameInterval);
    }

    if (cameraStart()) {
      cameraActive = true;
      success = true;
      message = "Camera started";
      displayShowStatus("Camera ON", TFT_GREEN);
      DEBUG_PRINTLN("Camera started");
    } else {
      message = "Camera start failed";
      DEBUG_PRINTLN("Camera start failed");
    }
  } else if (strcmp(action, "pause") == 0) {
    cameraPause();
    success = true;
    message = "Camera paused";
    displayShowStatus("Camera PAUSED", TFT_YELLOW);
    DEBUG_PRINTLN("Camera paused");
  } else if (strcmp(action, "stop") == 0) {
    cameraStop();
    cameraClearSink(); // âœ¨ sink ì„¤ì • ì´ˆê¸°í™”
    cameraActive = false;
    success = true;
    message = "Camera stopped";
    displayShowStatus("Camera OFF", TFT_YELLOW);
    DEBUG_PRINTLN("Camera stopped");
  }

  // ì‘ë‹µ ë°œí–‰
  publishControlResponse(requestId, "camera", action, success, message.c_str());
}

/**
 * ë§ˆì´í¬ ì œì–´ ì²˜ë¦¬ (ASR ëª¨ë“œ í¬í•¨)
 *
 * @param action ì•¡ì…˜ (start, pause, stop, start_asr, stop_asr)
 * @param requestId ìš”ì²­ ID
 * @param sessionId ASR ì„¸ì…˜ ID (start_asrì¼ ë•Œë§Œ ì‚¬ìš©)
 * @param wsUrl WebSocket URL (start_asrì¼ ë•Œë§Œ ì‚¬ìš©)
 */
void handleMicrophoneControl(const char *action, const char *requestId,
                             const char *sessionId, const char *wsUrl) {
  bool success = false;
  String message = "";

  if (strcmp(action, "start") == 0) {
    // ì¼ë°˜ ë§ˆì´í¬ ì‹œì‘
    if (audioStartMicrophone()) {
      microphoneActive = true;
      success = true;
      message = "Microphone started";
      displayShowStatus("Mic ON", TFT_GREEN);
      DEBUG_PRINTLN("Microphone started");
    } else {
      message = "Microphone start failed";
      DEBUG_PRINTLN("Microphone start failed");
    }
  } else if (strcmp(action, "start_asr") == 0) {
    // âœ¨ ASR ëª¨ë“œ ì‹œì‘
    DEBUG_PRINTLN("ğŸ¤ ASR ëª¨ë“œ ì‹œì‘ ìš”ì²­");
    DEBUG_PRINTF("   Session ID: %s\n", sessionId ? sessionId : "null");
    DEBUG_PRINTF("   WebSocket URL: %s\n", wsUrl ? wsUrl : "null");

    if (!sessionId || !wsUrl) {
      message = "ASR start failed: missing session_id or ws_url";
      DEBUG_PRINTLN("âŒ ASR ì‹œì‘ ì‹¤íŒ¨: session_id ë˜ëŠ” ws_url ì—†ìŒ");
    } else {
      // WebSocket ì—°ê²°
      if (websocketConnect(sessionId, wsUrl)) {
        // ASR ëª¨ë“œë¡œ ë§ˆì´í¬ ì‹œì‘
        if (audioStartASRMode()) {
          success = true;
          message = "ASR mode started";
          displayShowStatus("ASR Recording", TFT_GREEN);
          DEBUG_PRINTLN("âœ… ASR ëª¨ë“œ ì‹œì‘ ì™„ë£Œ");
        } else {
          message = "ASR mode start failed";
          DEBUG_PRINTLN("âŒ ASR ëª¨ë“œ ì‹œì‘ ì‹¤íŒ¨");
          websocketDisconnect();
        }
      } else {
        message = "WebSocket connection failed";
        DEBUG_PRINTLN("âŒ WebSocket ì—°ê²° ì‹¤íŒ¨");
      }
    }
  } else if (strcmp(action, "stop_asr") == 0) {
    // âœ¨ ASR ëª¨ë“œ ì¢…ë£Œ
    DEBUG_PRINTLN("ğŸ›‘ ASR ëª¨ë“œ ì¢…ë£Œ ìš”ì²­");

    audioStopASRMode();
    websocketDisconnect();

    success = true;
    message = "ASR mode stopped";
    displayShowStatus("ASR Stopped", TFT_YELLOW);
    DEBUG_PRINTLN("âœ… ASR ëª¨ë“œ ì¢…ë£Œ ì™„ë£Œ");
  } else if (strcmp(action, "pause") == 0) {
    audioPauseMicrophone();
    success = true;
    message = "Microphone paused";
    displayShowStatus("Mic PAUSED", TFT_YELLOW);
    DEBUG_PRINTLN("Microphone paused");
  } else if (strcmp(action, "stop") == 0) {
    audioStopMicrophone();
    microphoneActive = false;
    success = true;
    message = "Microphone stopped";
    displayShowStatus("Mic OFF", TFT_YELLOW);
    DEBUG_PRINTLN("Microphone stopped");
  }

  // ì‘ë‹µ ë°œí–‰
  publishControlResponse(requestId, "microphone", action, success,
                         message.c_str());
}

/**
 * ìŠ¤í”¼ì»¤ ì œì–´ ì²˜ë¦¬
 */
void handleSpeakerControl(const char *action, const char *audioUrl,
                          const char *requestId) {
  bool success = false;
  String message = "";

  if (strcmp(action, "play") == 0) {
    if (audioUrl && strlen(audioUrl) > 0) {
      // ë³¼ë¥¨ ì„¤ì •ì´ ìˆìœ¼ë©´ ì ìš© (JSONì—ì„œ volume í•„ë“œ í™•ì¸)
      // ì°¸ê³ : ì´ í•¨ìˆ˜ëŠ” ì´ë¯¸ JSONì—ì„œ íŒŒì‹±ëœ í›„ í˜¸ì¶œë¨

      if (audioPlayURL(audioUrl)) {
        success = true;
        message = "Speaker playing";
        displayShowStatus("Playing Audio", TFT_GREEN);
        DEBUG_PRINTF("Playing audio: %s\n", audioUrl);
      } else {
        message = "Audio playback failed";
        DEBUG_PRINTLN("Audio playback failed");
      }
    } else {
      message = "Audio URL required";
      DEBUG_PRINTLN("Audio URL required");
    }
  } else if (strcmp(action, "stop") == 0) {
    audioStopSpeaker();
    success = true;
    message = "Speaker stopped";
    displayShowStatus("Audio Stopped", TFT_YELLOW);
    DEBUG_PRINTLN("Speaker stopped");
  }

  // ì‘ë‹µ ë°œí–‰
  publishControlResponse(requestId, "speaker", action, success,
                         message.c_str());
}

/**
 * ë””ìŠ¤í”Œë ˆì´ ì œì–´ ì²˜ë¦¬
 */
void handleDisplayControl(const char *action, const char *content,
                          const char *emojiId, const char *requestId) {
  bool success = false;
  String message = "";

  if (strcmp(action, "show_text") == 0) {
    if (content && strlen(content) > 0) {
      displayShowText(content);
      success = true;
      message = "Text displayed";
      DEBUG_PRINTF("Displaying text: %s\n", content);
    } else {
      message = "Text content required";
      DEBUG_PRINTLN("Text content required");
    }
  } else if (strcmp(action, "show_emoji") == 0) {
    if (emojiId && strlen(emojiId) > 0) {
      displayShowEmoji(emojiId);
      success = true;
      message = "Emoji displayed";
      DEBUG_PRINTF("Displaying emoji: %s\n", emojiId);
    } else {
      message = "Emoji ID required";
      DEBUG_PRINTLN("Emoji ID required");
    }
  } else if (strcmp(action, "clear") == 0) {
    displayClear();
    success = true;
    message = "Display cleared";
    DEBUG_PRINTLN("Display cleared");
  }

  // ì‘ë‹µ ë°œí–‰
  publishControlResponse(requestId, "display", action, success,
                         message.c_str());
}

/**
 * ì‹œìŠ¤í…œ ì œì–´ ì²˜ë¦¬
 */
void handleSystemControl(const char *action, const char *requestId) {
  bool success = false;
  String message = "";

  if (strcmp(action, "restart") == 0) {
    success = true;
    message = "Device restarting";
    displayShowStatus("Restarting...", TFT_YELLOW);
    DEBUG_PRINTLN("Device restart requested");

    // ì‘ë‹µ ë°œí–‰
    publishControlResponse(requestId, "system", action, success,
                           message.c_str());

    // ì‘ë‹µ ì „ì†¡ ì™„ë£Œ ëŒ€ê¸°
    delay(1000);

    // ESP32 ì¬ì‹œì‘
    ESP.restart();
  } else {
    message = "Unknown system command";
    publishControlResponse(requestId, "system", action, false, message.c_str());
  }
}

/**
 * ì œì–´ ì‘ë‹µ ë°œí–‰
 */
void publishControlResponse(const char *requestId, const char *command,
                            const char *action, bool success,
                            const char *message) {
  extern PubSubClient mqttClient;

  StaticJsonDocument<256> doc;
  doc["request_id"] = requestId;
  doc["command"] = command;
  doc["action"] = action;
  doc["success"] = success;
  doc["message"] = message;
  doc["timestamp"] = millis() / 1000;

  char buffer[256];
  serializeJson(doc, buffer);

  mqttClient.publish(TOPIC_RESPONSE, buffer, MQTT_QOS);
  DEBUG_PRINTF("Published response: %s\n", buffer);
}

/**
 * ì˜¨ë¼ì¸ ìƒíƒœ ë°œí–‰
 */
void publishOnlineStatus(PubSubClient &client, bool isOnline) {
  StaticJsonDocument<128> doc;
  doc["device_id"] = DEVICE_ID;
  doc["online"] = isOnline;
  doc["timestamp"] = millis() / 1000;

  char buffer[128];
  serializeJson(doc, buffer);

  client.publish(TOPIC_STATUS, buffer, MQTT_QOS);
  DEBUG_PRINTF("Published online status: %s\n", isOnline ? "true" : "false");
}
