# -*- coding: utf-8 -*-
"""
VAD (Voice Activity Detection) í”„ë¡œì„¸ì„œ ëª¨ë“ˆ

ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ì„ ìœ„í•œ VAD ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ì„œ
"""

import logging
import threading
from datetime import datetime
from typing import Dict, Optional
from collections import deque
import numpy as np

logger = logging.getLogger(__name__)


class VADStreamingProcessor:
    """ì—ë„ˆì§€ ê¸°ë°˜ ê°„ë‹¨í•œ VADë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ í”„ë¡œì„¸ì„œ"""

    def __init__(self, recognizer, sample_rate=16000, vad_enabled=True):
        self.recognizer = recognizer
        self.sample_rate = sample_rate
        
        # ê°„ë‹¨í•œ ì—ë„ˆì§€ ê¸°ë°˜ VAD ì„¤ì •
        self.vad_enabled = vad_enabled
        self.energy_threshold = 0.01  # ì—ë„ˆì§€ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
        self.silence_duration = 1.5  # ì¹¨ë¬µ íŒë‹¨ ì‹œê°„ (ì´ˆ)
        self.min_speech_duration = 0.5  # ìµœì†Œ ìŒì„± ê¸¸ì´ (ì´ˆ)
        
        # ìŒì„± ë²„í¼
        self.audio_buffer = deque()
        self.speech_segments = []  # ìŒì„± êµ¬ê°„ ì €ì¥
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_session_active = False  # ì„¸ì…˜ í™œì„±í™” ìƒíƒœ
        self.is_processing = False  # ìŒì„± ì²˜ë¦¬ ì¤‘
        self.silence_frames = 0  # ì¹¨ë¬µ í”„ë ˆì„ ì¹´ìš´í„°
        self.speech_frames = 0  # ìŒì„± í”„ë ˆì„ ì¹´ìš´í„°
        self.last_result = ""
        self.lock = threading.Lock()
        
        logger.info(f"âœ… VADStreamingProcessor ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - VAD: ì—ë„ˆì§€ ê¸°ë°˜ ê°„ë‹¨í•œ VAD")
        logger.info(f"   - ì—ë„ˆì§€ ì„ê³„ê°’: {self.energy_threshold}")
        logger.info(f"   - ì¹¨ë¬µ ê°ì§€: {self.silence_duration}ì´ˆ")

    def _calculate_energy(self, audio_chunk: np.ndarray) -> float:
        """ì˜¤ë””ì˜¤ ì²­í¬ì˜ ì—ë„ˆì§€ ê³„ì‚° (RMS)"""
        return np.sqrt(np.mean(audio_chunk ** 2))

    def _is_speech(self, audio_chunk: np.ndarray) -> bool:
        """ì—ë„ˆì§€ ê¸°ë°˜ ìŒì„± ê°ì§€"""
        if not self.vad_enabled:
            return True
        
        energy = self._calculate_energy(audio_chunk)
        return energy > self.energy_threshold

    def start_session(self):
        """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ (ë§ˆì´í¬ ê³„ì† ì¼œì§)"""
        with self.lock:
            if self.is_session_active:
                logger.warning("âš ï¸ ì´ë¯¸ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                return False
            
            self.is_session_active = True
            self.is_processing = False
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.last_result = ""
            self.silence_frames = 0
            self.speech_frames = 0
            
            logger.info("=" * 60)
            logger.info("ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘")
            logger.info("   - ë§ˆì´í¬ í™œì„±í™”: ê³„ì† ë“£ê¸° ëª¨ë“œ")
            logger.info("   - ì—ë„ˆì§€ ê¸°ë°˜ VADë¡œ ìŒì„± ìë™ ê°ì§€")
            logger.info("=" * 60)
            return True

    def stop_session(self):
        """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ (ë§ˆì´í¬ ë”)"""
        with self.lock:
            if not self.is_session_active:
                logger.warning("âš ï¸ í™œì„±í™”ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            logger.info("â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")
            
            # ë‚¨ì€ ë²„í¼ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
            if len(self.audio_buffer) > 0 and self.is_processing:
                speech_audio = np.array(self.audio_buffer)
                duration = len(speech_audio) / self.sample_rate
                
                if duration >= self.min_speech_duration:
                    result = self._process_speech_segment(speech_audio)
                    if result:
                        self.speech_segments.append(result)
            
            self.is_session_active = False
            self.is_processing = False
            
            # ì„¸ì…˜ í†µê³„
            segment_count = len(self.speech_segments)
            total_duration = sum(seg.get('duration', 0) for seg in self.speech_segments)
            
            logger.info(f"ğŸ“Š ì„¸ì…˜ í†µê³„:")
            logger.info(f"   - ê°ì§€ëœ ìŒì„± êµ¬ê°„: {segment_count}ê°œ")
            logger.info(f"   - ì´ ìŒì„± ê¸¸ì´: {total_duration:.1f}ì´ˆ")
            
            result = {
                'segments': self.speech_segments.copy(),
                'total_segments': segment_count,
                'total_duration': total_duration
            }
            
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.silence_frames = 0
            self.speech_frames = 0
            
            return result

    def process_audio_chunk(self, audio_chunk: np.ndarray) -> Optional[Dict]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ (asr_api_server.pyì—ì„œ ì‚¬ìš©)
        
        Args:
            audio_chunk: float32 PCM ì˜¤ë””ì˜¤ ë°ì´í„° (16kHz)
        
        Returns:
            ìŒì„± ê°ì§€ ë° ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        return self.add_audio_chunk(audio_chunk)

    def add_audio_chunk(self, audio_chunk: np.ndarray) -> Optional[Dict]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° VAD ê¸°ë°˜ ì²˜ë¦¬
        
        Returns:
            ìŒì„± ê°ì§€ ë° ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        with self.lock:
            if not self.is_session_active:
                return None
            
            try:
                # ìŒì„± í™œë™ ê°ì§€
                is_speech = self._is_speech(audio_chunk)
                
                if is_speech:
                    # ìŒì„±ì´ ê°ì§€ë˜ë©´
                    self.silence_frames = 0
                    self.speech_frames += 1
                    
                    if not self.is_processing:
                        # ìƒˆë¡œìš´ ìŒì„± êµ¬ê°„ ì‹œì‘
                        self.is_processing = True
                        self.audio_buffer.clear()
                        logger.info("ğŸ—£ï¸ ìŒì„± ê°ì§€ ì‹œì‘")
                    
                    self.audio_buffer.extend(audio_chunk)
                else:
                    # ì¹¨ë¬µì´ ê°ì§€ë˜ë©´
                    self.silence_frames += 1
                    
                    if self.is_processing:
                        # ìŒì„± ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° ë²„í¼ì— ì¶”ê°€ (ì§§ì€ ì¹¨ë¬µ í¬í•¨)
                        self.audio_buffer.extend(audio_chunk)
                        
                        # ì¹¨ë¬µ ì‹œê°„ ê³„ì‚°
                        silence_duration = (self.silence_frames * len(audio_chunk)) / self.sample_rate
                        
                        # ì¶©ë¶„í•œ ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ ìŒì„± êµ¬ê°„ ì²˜ë¦¬
                        if silence_duration >= self.silence_duration:
                            speech_audio = np.array(self.audio_buffer)
                            duration = len(speech_audio) / self.sample_rate
                            
                            if duration >= self.min_speech_duration:
                                result = self._process_speech_segment(speech_audio)
                                
                                if result:
                                    logger.info(f"âœ… ìŒì„± ì²˜ë¦¬ ì™„ë£Œ ({duration:.1f}ì´ˆ)")
                                    self.speech_segments.append(result)
                                    self.is_processing = False
                                    self.audio_buffer.clear()
                                    self.silence_frames = 0
                                    self.speech_frames = 0
                                    return result
                            else:
                                logger.debug(f"â­ï¸ ë„ˆë¬´ ì§§ì€ ìŒì„± ë¬´ì‹œ ({duration:.1f}ì´ˆ)")
                            
                            self.is_processing = False
                            self.audio_buffer.clear()
                            self.silence_frames = 0
                            self.speech_frames = 0
                
            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                return None
        
        return None

    def _process_speech_segment(self, audio_data: np.ndarray) -> Optional[Dict]:
        """ìŒì„± êµ¬ê°„ ì²˜ë¦¬ ë° ì¸ì‹"""
        try:
            duration = len(audio_data) / self.sample_rate
            
            # ìŒì„±ì¸ì‹ ìˆ˜í–‰
            stream = self.recognizer.create_stream()
            stream.accept_waveform(self.sample_rate, audio_data)
            self.recognizer.decode_stream(stream)
            result = stream.result
            
            text = result.text.strip()
            
            if text:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                segment_result = {
                    'timestamp': timestamp,
                    'text': text,
                    'duration': duration,
                    'confidence': 1.0  # Sherpa-ONNXëŠ” confidence scoreë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                }
                
                logger.info(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")
                self.last_result = text
                
                return segment_result
            else:
                logger.debug("ğŸ”‡ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
                return None
        
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def get_session_status(self) -> Dict:
        """í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            return {
                'is_active': self.is_session_active,
                'is_processing': self.is_processing,
                'segments_count': len(self.speech_segments),
                'last_result': self.last_result
            }

    def reset(self):
        """ì™„ì „ ì´ˆê¸°í™”"""
        with self.lock:
            logger.info("ğŸ”„ VADStreamingProcessor ì´ˆê¸°í™”")
            self.is_session_active = False
            self.is_processing = False
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.last_result = ""
            self.silence_frames = 0
            self.speech_frames = 0


class StreamingProcessor:
    """Offline Recognizerë¥¼ ì‚¬ìš©í•œ ì²­í¬ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ë ˆê±°ì‹œ)"""

    def __init__(self, recognizer, sample_rate=16000, chunk_duration=20.0):
        self.recognizer = recognizer
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.chunk_size = int(sample_rate * chunk_duration)

        self.audio_buffer = deque()
        self.is_recording = False
        self.is_ready = False
        self.accumulated_audio = []
        self.last_result = ""
        self.lock = threading.Lock()

        logger.info(f"âœ… StreamingProcessor ì´ˆê¸°í™” (ì²­í¬ í¬ê¸°: {chunk_duration}ì´ˆ)")
        logger.debug(f"ì´ˆê¸° ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

    def prepare(self):
        """ë…¹ìŒ ì¤€ë¹„ (is_recordingì€ False ìœ ì§€)"""
        with self.lock:
            old_state = (self.is_ready, self.is_recording)

            self.is_ready = True
            self.is_recording = False
            self.audio_buffer.clear()
            self.accumulated_audio.clear()
            self.last_result = ""

            new_state = (self.is_ready, self.is_recording)

            logger.info("=" * 60)
            logger.info("ğŸŸ¡ ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ")
            logger.debug(f"ìƒíƒœ ë³€ê²½: {old_state} â†’ {new_state}")
            logger.debug(f"ë²„í¼ ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info("=" * 60)

    def start_recording(self):
        """ë…¹ìŒ ì‹œì‘ (ë§ˆì´í¬ í™œì„±í™” ì‹œ í˜¸ì¶œ)"""
        with self.lock:
            if not self.is_ready:
                logger.warning("âš ï¸ ì¤€ë¹„ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ë…¹ìŒ ì‹œì‘ ì‹œë„")
                logger.debug(f"í˜„ì¬ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")
                return False

            old_state = self.is_recording
            self.is_recording = True

            logger.info("=" * 60)
            logger.info("ğŸ”´ ë…¹ìŒ ì‹œì‘")
            logger.debug(f"is_recording: {old_state} â†’ {self.is_recording}")
            logger.info("=" * 60)
            return True

    def stop_recording(self):
        """ë…¹ìŒ ì¢…ë£Œ ë° ìµœì¢… ì²˜ë¦¬"""
        with self.lock:
            logger.info("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ìš”ì²­")
            logger.debug(f"í˜„ì¬ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

            if not self.is_recording:
                logger.warning("ë…¹ìŒ ì¤‘ì´ ì•„ë‹Œ ìƒíƒœì—ì„œ ì¢…ë£Œ ìš”ì²­")
                return None

            self.is_recording = False
            self.is_ready = False

            logger.debug(f"ìƒíƒœ ë³€ê²½: is_recording={True} â†’ {False}, is_ready={True} â†’ {False}")

            # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬
            if len(self.accumulated_audio) > 0:
                final_audio = np.concatenate(self.accumulated_audio)
                duration = len(final_audio) / self.sample_rate
                logger.info(f"ìµœì¢… ì˜¤ë””ì˜¤ ì²˜ë¦¬: {duration:.2f}ì´ˆ")

                result = self._process_audio(final_audio)
                logger.info(f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ - ìµœì¢… ê¸¸ì´: {duration:.2f}ì´ˆ")
                return result

            logger.warning("ëˆ„ì ëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŒ")
            return self.last_result

    def add_audio_chunk(self, audio_chunk: np.ndarray) -> Optional[str]:
        """ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° ì²˜ë¦¬"""
        with self.lock:
            # is_readyì´ë©´ì„œ is_recording=Falseì¸ ê²½ìš°: ì²« ì˜¤ë””ì˜¤ ë„ì°© ì‹œ ìë™ ì‹œì‘
            if self.is_ready and not self.is_recording:
                self.is_recording = True
                logger.info("ğŸ¤ ë§ˆì´í¬ í™œì„±í™” ê°ì§€ â†’ ìë™ ë…¹ìŒ ì‹œì‘")
                logger.debug(f"is_recording: False â†’ True (ìë™ ì „í™˜)")

            if not self.is_recording:
                logger.debug(f"ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ (is_ready={self.is_ready})")
                return None

            try:
                # ë²„í¼ì— ì¶”ê°€
                chunk_len = len(audio_chunk)
                self.audio_buffer.extend(audio_chunk)
                self.accumulated_audio.append(audio_chunk)

                logger.debug(f"ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€: {chunk_len} samples, ëˆ„ì : {len(self.accumulated_audio)} chunks")

                # ì²­í¬ í¬ê¸° ì¶©ì¡± ì‹œ ì²˜ë¦¬
                if len(self.audio_buffer) >= self.chunk_size:
                    logger.debug(f"ì²­í¬ í¬ê¸° ë„ë‹¬: {len(self.audio_buffer)} >= {self.chunk_size}")

                    # ì „ì²´ ëˆ„ì  ì˜¤ë””ì˜¤ë¡œ ì²˜ë¦¬ (ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸)
                    full_audio = np.concatenate(self.accumulated_audio)
                    result = self._process_audio(full_audio)

                    # ë²„í¼ ì¼ë¶€ë§Œ ìœ ì§€ (overlap)
                    overlap_size = self.chunk_size // 4
                    self.audio_buffer = deque(list(self.audio_buffer)[self.chunk_size - overlap_size:])

                    logger.debug(f"ë²„í¼ ì—…ë°ì´íŠ¸: overlap={overlap_size}, ë‚¨ì€ ë²„í¼={len(self.audio_buffer)}")

                    if result and result != self.last_result:
                        self.last_result = result
                        logger.info(f"ìƒˆë¡œìš´ ì¸ì‹ ê²°ê³¼: {result[:50]}...")
                        return result

            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                return None

        return None

    def _process_audio(self, audio_data: np.ndarray) -> str:
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬"""
        try:
            duration = len(audio_data) / self.sample_rate
            logger.debug(f"ìŒì„±ì¸ì‹ ì²˜ë¦¬ ì‹œì‘: {duration:.2f}ì´ˆ")

            if duration < 0.5:
                logger.debug("ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ 0.5ì´ˆ ë¯¸ë§Œ, ì²˜ë¦¬ ê±´ë„ˆëœ€")
                return ""

            # Offline Recognizerë¡œ ì²˜ë¦¬
            stream = self.recognizer.create_stream()
            stream.accept_waveform(self.sample_rate, audio_data)
            self.recognizer.decode_stream(stream)
            result = stream.result

            text = result.text.strip()
            logger.debug(f"ìŒì„±ì¸ì‹ ê²°ê³¼: '{text}'")
            return text

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            return ""

    def get_current_duration(self) -> float:
        """í˜„ì¬ ë…¹ìŒ ê¸¸ì´ ë°˜í™˜"""
        if len(self.accumulated_audio) > 0:
            total_samples = sum(len(chunk) for chunk in self.accumulated_audio)
            duration = total_samples / self.sample_rate
            logger.debug(f"í˜„ì¬ ë…¹ìŒ ê¸¸ì´: {duration:.2f}ì´ˆ ({len(self.accumulated_audio)} chunks)")
            return duration
        return 0.0

    def reset(self):
        """ì™„ì „ ì´ˆê¸°í™”"""
        with self.lock:
            logger.info("ğŸ”„ StreamingProcessor ì™„ì „ ì´ˆê¸°í™”")
            logger.debug(f"ì´ˆê¸°í™” ì „ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

            self.is_recording = False
            self.is_ready = False
            self.audio_buffer.clear()
            self.accumulated_audio.clear()
            self.last_result = ""

            logger.debug("ì´ˆê¸°í™” ì™„ë£Œ: is_ready=False, is_recording=False, ë²„í¼ ë¹„ì›€")

