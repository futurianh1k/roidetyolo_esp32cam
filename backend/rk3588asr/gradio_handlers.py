# -*- coding: utf-8 -*-
"""
Gradio UI í•¸ë“¤ëŸ¬ ëª¨ë“ˆ

Gradio UIì˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤
"""

import os
import time
import logging
import gradio as gr
import numpy as np
import soundfile as sf
from datetime import datetime
from typing import Optional

from .config import LANGUAGE_MAP, GROUND_TRUTHS, LABELS
from .model_loader import recognizer, vad_stream_processor
from .vad_processor import StreamingProcessor
from .session_manager import (
    mic_session_recorder,
    clear_vad_chat_history,
    add_to_vad_chat_history,
    format_vad_chat_history,
)
from .matcher import SpeechRecognitionMatcher
from .emergency_alert import send_emergency_alert
from .report_generator import generate_mic_session_csv_report, generate_batch_csv_report
from .utils import resample_audio, read_wave

logger = logging.getLogger(__name__)

# ì „ì—­ matcher ì¸ìŠ¤í„´ìŠ¤
matcher = SpeechRecognitionMatcher(GROUND_TRUTHS, LABELS)

# ì „ì—­ ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ (ë ˆê±°ì‹œ)
stream_processor: Optional[StreamingProcessor] = None

# ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ì†Œ
batch_results_storage = {
    "file_names": [],
    "ground_truths": [],
    "asr_results": []
}


# ====================
# VAD ê¸°ë°˜ í•¸ë“¤ëŸ¬
# ====================

def start_vad_session_handler():
    """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ í•¸ë“¤ëŸ¬ (VAD ê¸°ë°˜)"""
    logger.info("=" * 60)
    logger.info("ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ ìš”ì²­")

    if vad_stream_processor is None:
        logger.error("VADStreamingProcessorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ìŒì„±ì¸ì‹ ì‹œì‘"),
            gr.update(interactive=False),
            None,
            "âŒ ì˜¤ë¥˜: ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        ]
    
    # ì„¸ì…˜ ì‹œì‘
    success = vad_stream_processor.start_session()
    
    if success:
        session_count = mic_session_recorder.get_session_count()
        status_msg = (
            "ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™”!\n\n"
            "âœ… ë§ˆì´í¬ê°€ ê³„ì† ì¼œì ¸ ìˆìŠµë‹ˆë‹¤.\n"
            "âœ… ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n"
            "âœ… VADê°€ ìŒì„±ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤.\n\n"
            "ğŸ”´ ìŒì„±ì¸ì‹ ì¢…ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„¸ì…˜ì„ ì¢…ë£Œí•˜ì„¸ìš”.\n\n"
            f"ğŸ“Š ì´ì „ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
        )
        
        logger.info("âœ… ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ ì„±ê³µ")
        logger.info("=" * 60)
        
        return [
            gr.update(interactive=False, value="ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘..."),
            gr.update(interactive=True),
            None,
            status_msg
        ]
    else:
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ìŒì„±ì¸ì‹ ì‹œì‘"),
            gr.update(interactive=False),
            None,
            "âš ï¸ ì„¸ì…˜ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        ]


def stop_vad_session_handler(ground_truth_input):
    """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ í•¸ë“¤ëŸ¬ (VAD ê¸°ë°˜)"""
    logger.info("â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")

    if vad_stream_processor is None:
        logger.error("VADStreamingProcessorê°€ None")
        return [
            "âš ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.",
            ""
        ]

    # ì„¸ì…˜ ì¢…ë£Œ
    session_result = vad_stream_processor.stop_session()
    
    if session_result:
        segments = session_result.get('segments', [])
        total_segments = session_result.get('total_segments', 0)
        total_duration = session_result.get('total_duration', 0)
        
        # ê° êµ¬ê°„ì— ëŒ€í•œ ì‘ê¸‰ ìƒí™© ì²´í¬
        emergency_detected = False
        emergency_segments = []
        
        result_text = f"â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ\n\n"
        result_text += f"ğŸ“Š ì„¸ì…˜ í†µê³„:\n"
        result_text += f"   - ê°ì§€ëœ ìŒì„± êµ¬ê°„: {total_segments}ê°œ\n"
        result_text += f"   - ì´ ìŒì„± ê¸¸ì´: {total_duration:.1f}ì´ˆ\n\n"
        
        if segments:
            result_text += "ğŸ“ ì¸ì‹ ê²°ê³¼:\n"
            result_text += "=" * 60 + "\n\n"
            
            for idx, seg in enumerate(segments, 1):
                text = seg.get('text', '')
                timestamp = seg.get('timestamp', '')
                duration = seg.get('duration', 0)
                
                result_text += f"[{idx}] {timestamp} ({duration:.1f}ì´ˆ)\n"
                result_text += f"    {text}\n\n"
                
                # ì‘ê¸‰ ìƒí™© ì²´í¬
                match_result = matcher.find_best_match(text)
                if match_result.get("is_emergency", False):
                    emergency_detected = True
                    emergency_keywords = match_result.get("emergency_keywords", [])
                    emergency_segments.append({
                        'index': idx,
                        'text': text,
                        'keywords': emergency_keywords,
                        'timestamp': timestamp
                    })
                    
                    logger.warning(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ [êµ¬ê°„ {idx}]: {emergency_keywords}")
        else:
            result_text += "âš ï¸ ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.\n"
        
        # ì‘ê¸‰ ìƒí™© ìš”ì•½
        if emergency_detected:
            result_text += "\n" + "=" * 60 + "\n"
            result_text += "ğŸš¨ğŸš¨ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! ğŸš¨ğŸš¨ğŸš¨\n\n"
            for emerg in emergency_segments:
                result_text += f"[êµ¬ê°„ {emerg['index']}] {emerg['timestamp']}\n"
                result_text += f"   í‚¤ì›Œë“œ: {', '.join(emerg['keywords'])}\n"
                result_text += f"   ë‚´ìš©: {emerg['text']}\n\n"
            result_text += "âœ… ì‘ê¸‰ ì•Œë¦¼ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        
        # ì„¸ì…˜ ê²°ê³¼ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹¨)
        if segments:
            combined_text = " ".join([seg.get('text', '') for seg in segments])
            gt = ground_truth_input.strip() if ground_truth_input else "(ì •ë‹µ ë¯¸ì…ë ¥)"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            mic_session_recorder.add_session_result(
                ground_truth=gt,
                asr_result=combined_text,
                duration=total_duration,
                timestamp=timestamp
            )
        
        session_count = mic_session_recorder.get_session_count()
        result_text += f"\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        clear_vad_chat_history()
        
        logger.info("âœ… ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ì™„ë£Œ")
        
        return [
            result_text,
            ""  # ground_truth ì´ˆê¸°í™”
        ]
    else:
        session_count = mic_session_recorder.get_session_count()
        clear_vad_chat_history()
        
        return [
            f"â¹ï¸ ì„¸ì…˜ ì¢…ë£Œ\n\nâš ï¸ í™œì„±í™”ëœ ì„¸ì…˜ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""
        ]


def reset_vad_session_handler():
    """VAD ì„¸ì…˜ ë¦¬ì…‹ í•¸ë“¤ëŸ¬"""
    logger.info("ğŸ”„ VAD ì„¸ì…˜ ë¦¬ì…‹ ìš”ì²­")

    if vad_stream_processor is None:
        return [
            None,
            "âš ï¸ ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            ""
        ]
    
    vad_stream_processor.reset()
    clear_vad_chat_history()
    session_count = mic_session_recorder.get_session_count()
    
    return [
        None,  # audio ì»´í¬ë„ŒíŠ¸ ë¦¬ì…‹
        f"ğŸ”„ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në§ˆì´í¬ ë²„íŠ¼ì„ ë‹¤ì‹œ í´ë¦­í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.\n\nğŸ“Š ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
        ""  # ground_truth ì´ˆê¸°í™”
    ]


def process_vad_audio_stream(audio_stream, language):
    """VAD ê¸°ë°˜ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
    if audio_stream is None:
        yield ""
        return

    try:
        sr, audio_data = audio_stream

        if audio_data is None or len(audio_data) == 0:
            yield ""
            return

        # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)

        # float32 ì •ê·œí™”
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        elif audio_data.dtype == np.int32:
            audio_data = audio_data.astype(np.float32) / 2147483648.0
        elif audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            audio_data = resample_audio(audio_data, sr, 16000)

        # í”„ë¡œì„¸ì„œ í™•ì¸
        if not vad_stream_processor:
            yield ""
            return

        # ì„¸ì…˜ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ ì‹œì‘
        status = vad_stream_processor.get_session_status()
        if not status['is_active']:
            logger.info("ğŸ¤ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê°ì§€ - ìë™ìœ¼ë¡œ ì„¸ì…˜ ì‹œì‘")
            vad_stream_processor.start_session()
            clear_vad_chat_history()
            
            session_count = mic_session_recorder.get_session_count()
            yield (
                "ğŸ¤ ìŒì„±ì¸ì‹ ìë™ ì‹œì‘!\n\n"
                "âœ… ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n\n"
                "ğŸ—£ï¸ ì§€ê¸ˆ ë§ì”€í•´ì£¼ì„¸ìš”...\n\n"
                f"ğŸ“Š ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
            )
            status = vad_stream_processor.get_session_status()

        # ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ (VAD ê¸°ë°˜)
        result = vad_stream_processor.add_audio_chunk(audio_data)
        
        segments_count = status['segments_count']
        is_processing = status['is_processing']
        
        if result:
            # ìƒˆë¡œìš´ ìŒì„± êµ¬ê°„ ì¸ì‹ ì™„ë£Œ
            text = result.get('text', '')
            duration = result.get('duration', 0)
            timestamp = result.get('timestamp', '')
            
            # ì‘ê¸‰ ìƒí™© ì‹¤ì‹œê°„ ì²´í¬
            match_result = matcher.find_best_match(text)
            is_emergency = False
            emergency_keywords = []
            
            if match_result.get("is_emergency", False):
                is_emergency = True
                emergency_keywords = match_result.get("emergency_keywords", [])
                logger.warning(f"ğŸš¨ ì‹¤ì‹œê°„ ì‘ê¸‰ ìƒí™© ê°ì§€! í‚¤ì›Œë“œ: {emergency_keywords}")
                
                # API í˜¸ì¶œ
                send_emergency_alert(text, emergency_keywords)
            
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            add_to_vad_chat_history(timestamp, text, duration, is_emergency, emergency_keywords)
            
            # ëˆ„ì ëœ íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥
            output = format_vad_chat_history()
            
            logger.info(f"ğŸ¤ VAD ì¸ì‹ ì™„ë£Œ: {text}")
            yield output
        else:
            # ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜ ëŒ€ê¸° ì¤‘ì¼ ë•Œ
            # format_vad_chat_history()ëŠ” ë‚´ë¶€ì—ì„œ vad_chat_historyë¥¼ í™•ì¸í•¨
            output = format_vad_chat_history()
            
            if output != "ğŸ‘‚ ëŒ€ê¸° ì¤‘... ë§ì”€í•´ì£¼ì„¸ìš”.":
                # íˆìŠ¤í† ë¦¬ê°€ ìˆëŠ” ê²½ìš°
                if is_processing:
                    output += "\n\nğŸ—£ï¸ ìŒì„± ê°ì§€ ì¤‘... ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤."
                
                yield output
            else:
                # íˆìŠ¤í† ë¦¬ê°€ ì—†ëŠ” ê²½ìš°
                if is_processing:
                    yield (
                        "ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘...\n\n"
                        "ğŸ—£ï¸ ìŒì„± ê°ì§€ ì¤‘... ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤."
                    )
                else:
                    yield output  # "ğŸ‘‚ ëŒ€ê¸° ì¤‘... ë§ì”€í•´ì£¼ì„¸ìš”."

    except Exception as e:
        logger.error(f"âŒ VAD ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        yield f"âŒ ì˜¤ë¥˜: {str(e)}"


# ====================
# ë ˆê±°ì‹œ í•¸ë“¤ëŸ¬
# ====================

def start_recording_handler():
    """ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í•¸ë“¤ëŸ¬ (ë ˆê±°ì‹œ)"""
    global stream_processor

    logger.info("=" * 60)
    logger.info("ğŸŸ¡ ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í´ë¦­")

    if stream_processor is not None:
        logger.debug("ê¸°ì¡´ StreamingProcessor ì¬ì‚¬ìš©")
        stream_processor.prepare()
    else:
        logger.warning("StreamingProcessorê°€ None, ìƒˆë¡œ ìƒì„±")
        stream_processor = StreamingProcessor(recognizer, chunk_duration=20.0)
        stream_processor.prepare()

    logger.info(f"âœ… ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ: is_ready={stream_processor.is_ready}, is_recording={stream_processor.is_recording}")
    logger.info("=" * 60)

    session_count = mic_session_recorder.get_session_count()
    status_msg = f"ğŸŸ¡ ì¤€ë¹„ ì™„ë£Œ!\n\në§ˆì´í¬ ë²„íŠ¼(ğŸ¤)ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”.\n2ì´ˆë§ˆë‹¤ ì‹¤ì‹œê°„ ì¸ì‹ë©ë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"

    return [
        gr.update(interactive=False, value="ğŸŸ¡ ì¤€ë¹„ ì™„ë£Œ - ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"),
        gr.update(interactive=True),
        None,  # Audio ì»´í¬ë„ŒíŠ¸ ë¦¬ì…‹
        status_msg
    ]


def stop_recording_handler(ground_truth_input):
    """ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ í•¸ë“¤ëŸ¬"""
    global stream_processor

    logger.info("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ í´ë¦­")

    if stream_processor is None:
        logger.error("StreamingProcessorê°€ None")
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            "âš ï¸ ë…¹ìŒ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.",
            ""  # ground_truth ì´ˆê¸°í™”
        ]

    logger.debug(f"ì¢…ë£Œ ì „ ìƒíƒœ: is_ready={stream_processor.is_ready}, is_recording={stream_processor.is_recording}")

    if stream_processor.is_ready and not stream_processor.is_recording:
        logger.warning("ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì€ ìƒíƒœì—ì„œ ì¢…ë£Œ")
        stream_processor.reset()
        session_count = mic_session_recorder.get_session_count()
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"âš ï¸ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì•„ ë…¹ìŒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]

    # ì •ìƒ ë…¹ìŒ ì¢…ë£Œ
    final_text = stream_processor.stop_recording()
    duration = stream_processor.get_current_duration()

    if final_text:
        # ì„¸ì…˜ ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        gt = ground_truth_input.strip() if ground_truth_input else "(ì •ë‹µ ë¯¸ì…ë ¥)"

        mic_session_recorder.add_session_result(
            ground_truth=gt,
            asr_result=final_text,
            duration=duration,
            timestamp=timestamp
        )

        match_result = matcher.find_best_match(final_text)
        logger.info(f"â¹ï¸ ìµœì¢… ê²°ê³¼ ({duration:.1f}ì´ˆ): {match_result}")

        # ì‘ê¸‰ ìƒí™© ê°ì§€ ì‹œ API í˜¸ì¶œ
        if match_result.get("is_emergency", False):
            emergency_keywords = match_result.get("emergency_keywords", [])
            logger.warning(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! í‚¤ì›Œë“œ: {emergency_keywords}")
            send_emergency_alert(final_text, emergency_keywords)

        session_count = mic_session_recorder.get_session_count()

        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ({duration:.1f}ì´ˆ)\n\nâœ… ìµœì¢… ê²°ê³¼:\n{final_text}\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]
    else:
        logger.warning("ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
        session_count = mic_session_recorder.get_session_count()
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ\n\nâš ï¸ ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]


def collect_and_process_audio(audio_stream, language):
    """ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ìˆ˜ì§‘ ë° ì‹¤ì‹œê°„ ì²˜ë¦¬ (ë ˆê±°ì‹œ)"""
    global stream_processor

    if audio_stream is None:
        yield ""
        return

    try:
        sr, audio_data = audio_stream

        if audio_data is None or len(audio_data) == 0:
            yield ""
            return

        logger.debug(f"ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} samples, {sr}Hz")

        # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
            logger.debug("ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜")

        # float32 ì •ê·œí™”
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        elif audio_data.dtype == np.int32:
            audio_data = audio_data.astype(np.float32) / 2147483648.0
        elif audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            audio_data = resample_audio(audio_data, sr, 16000)
            logger.debug(f"ë¦¬ìƒ˜í”Œë§: {sr}Hz â†’ 16000Hz")

        # í”„ë¡œì„¸ì„œ ì¤€ë¹„ í™•ì¸
        if not stream_processor or not stream_processor.is_ready:
            logger.debug(f"í”„ë¡œì„¸ì„œ ì¤€ë¹„ ì•ˆ ë¨")
            yield ""
            return

        # ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
        result_text = stream_processor.add_audio_chunk(audio_data)
        duration = stream_processor.get_current_duration()

        if result_text:
            match_result = matcher.find_best_match(result_text)
            logger.info(f"ğŸ¤ ì‹¤ì‹œê°„ ì¸ì‹ ({duration:.1f}ì´ˆ): {match_result}")
            
            # ì‘ê¸‰ ìƒí™© ê°ì§€ ì‹œ API í˜¸ì¶œ
            if match_result.get("is_emergency", False):
                emergency_keywords = match_result.get("emergency_keywords", [])
                logger.warning(f"ğŸš¨ ì‹¤ì‹œê°„ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! í‚¤ì›Œë“œ: {emergency_keywords}")
                send_emergency_alert(result_text, emergency_keywords)
            
            yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nâœ… ì‹¤ì‹œê°„ ì¸ì‹:\n{result_text}"
        else:
            last = stream_processor.last_result
            if last:
                yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nâœ… í˜„ì¬ ì¸ì‹:\n{last}"
            else:
                if stream_processor.is_recording:
                    yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nëŒ€ê¸° ì¤‘..."
                else:
                    yield ""

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        yield f"âŒ ì˜¤ë¥˜: {str(e)}"


# ====================
# íŒŒì¼ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
# ====================

def _resolve_file_path(audio_file):
    """íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ"""
    if isinstance(audio_file, dict):
        return audio_file.get("path") or audio_file.get("name")
    if hasattr(audio_file, "name"):
        return audio_file.name
    return audio_file


def transcribe_file(audio_file, language):
    """íŒŒì¼ ì—…ë¡œë“œ ìŒì„±ì¸ì‹"""
    start_time = time.time()

    try:
        if audio_file is None:
            return "âš ï¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        file_path = _resolve_file_path(audio_file)
        if not file_path or not os.path.exists(file_path):
            return f"âŒ íŒŒì¼ ê²½ë¡œ ì˜¤ë¥˜: {file_path}"

        logger.info(f"â±ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")

        # íŒŒì¼ ì½ê¸°
        try:
            audio_data, sr = sf.read(file_path)
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)
            samples = audio_data.astype(np.float32)
            sample_rate = sr
        except Exception as e1:
            logger.warning(f"soundfile ì‹¤íŒ¨: {e1}, wave ì‹œë„")
            try:
                samples, sample_rate = read_wave(file_path)
            except Exception as e2:
                raise Exception(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨. soundfile: {e1}, wave: {e2}")

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sample_rate != 16000:
            logger.info(f"ğŸ”„ ë¦¬ìƒ˜í”Œë§: {sample_rate} Hz â†’ 16000 Hz")
            samples = resample_audio(samples, sample_rate, 16000)
            sample_rate = 16000

        duration = len(samples) / sample_rate
        logger.info(f"ğŸ¤ ìŒì„±ì¸ì‹ ì‹œì‘ - ê¸¸ì´: {duration:.2f}ì´ˆ")

        # Offline Recognizerë¡œ ì²˜ë¦¬
        stream = recognizer.create_stream()
        stream.accept_waveform(sample_rate, samples)
        recognizer.decode_stream(stream)
        result = stream.result

        text = result.text.strip()

        # ì •ë‹µ ë§¤ì¹­
        match_result = matcher.find_best_match(text)

        if not text:
            text = "âš ï¸ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        file_name = os.path.basename(file_path)
        logger.info(f"ğŸ“ {file_name}\n{match_result}\n")

        total_time = time.time() - start_time
        logger.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {text}")
        logger.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")

        return text

    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        return f"âŒ ì˜¤ë¥˜: {str(e)}"


def batch_transcribe(files, language):
    """ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬"""
    global batch_results_storage

    if not files:
        return "âš ï¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    # ê²°ê³¼ ì´ˆê¸°í™”
    batch_results_storage = {
        "file_names": [],
        "ground_truths": [],
        "asr_results": []
    }

    results = []
    total = len(files)

    for idx, file in enumerate(files, 1):
        try:
            file_path = _resolve_file_path(file)
            file_name = os.path.basename(file_path)
            logger.info(f"[{idx}/{total}] ì²˜ë¦¬ ì¤‘: {file_name}")

            # íŒŒì¼ ì½ê¸°
            try:
                audio_data, sr = sf.read(file_path)
                if len(audio_data.shape) > 1:
                    audio_data = np.mean(audio_data, axis=1)
                samples = audio_data.astype(np.float32)
                sample_rate = sr
            except Exception:
                try:
                    samples, sample_rate = read_wave(file_path)
                except Exception as e:
                    raise Exception(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

            if sample_rate != 16000:
                samples = resample_audio(samples, sample_rate, 16000)
                sample_rate = 16000

            # Offline ì²˜ë¦¬
            stream = recognizer.create_stream()
            stream.accept_waveform(sample_rate, samples)
            recognizer.decode_stream(stream)
            result = stream.result
            text = result.text.strip()

            # ì •ë‹µ ë§¤ì¹­
            match_result = matcher.find_best_match(text)
            best_match = match_result.get("best_match", "")

            if not text:
                text = "(ìŒì„± ì¸ì‹ ì‹¤íŒ¨)"

            # ê²°ê³¼ ì €ì¥
            batch_results_storage["file_names"].append(file_name)
            batch_results_storage["ground_truths"].append(best_match)
            batch_results_storage["asr_results"].append(text)

            results.append(f"ğŸ“ **{file_name}**\n{text}\n")
            logger.info(f"ğŸ“ **{file_name}**\n{match_result}\n")

        except Exception as e:
            results.append(f"ğŸ“ **{file_name}**\nâŒ ì˜¤ë¥˜: {str(e)}\n")
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_name} - {e}")

            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì €ì¥
            batch_results_storage["file_names"].append(file_name)
            batch_results_storage["ground_truths"].append("")
            batch_results_storage["asr_results"].append(f"ERROR: {str(e)}")

    output = f"âœ… ì´ {total}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ\n\n" + "\n".join(results)
    return output


# ====================
# CSV ë¦¬í¬íŠ¸ í•¸ë“¤ëŸ¬
# ====================

def generate_mic_csv_handler():
    """ë§ˆì´í¬ ì„¸ì…˜ CSV ë¦¬í¬íŠ¸ ìƒì„± í•¸ë“¤ëŸ¬"""
    sessions = mic_session_recorder.get_all_sessions()

    if not sessions:
        return None, "âš ï¸ ìƒì„±í•  ì„¸ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë…¹ìŒ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”."

    # CSV ìƒì„±
    csv_path = generate_mic_session_csv_report(sessions, matcher)

    if csv_path and os.path.exists(csv_path):
        return csv_path, f"âœ… CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\n\nğŸ“Š ì´ {len(sessions)}ê°œ ì„¸ì…˜ ì²˜ë¦¬\nğŸ“ íŒŒì¼: {csv_path}"
    else:
        return None, "âŒ CSV ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"


def clear_mic_sessions_handler():
    """ë§ˆì´í¬ ì„¸ì…˜ ê²°ê³¼ ì´ˆê¸°í™” í•¸ë“¤ëŸ¬"""
    mic_session_recorder.clear_sessions()
    return "âœ… ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”."


def generate_batch_csv_handler():
    """ë°°ì¹˜ í…ŒìŠ¤íŠ¸ CSV ë¦¬í¬íŠ¸ ìƒì„± í•¸ë“¤ëŸ¬"""
    if not batch_results_storage["file_names"]:
        return None, "âš ï¸ ìƒì„±í•  ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°°ì¹˜ ë³€í™˜ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."

    # CSV ìƒì„±
    csv_path = generate_batch_csv_report(
        file_names=batch_results_storage["file_names"],
        ground_truths=batch_results_storage["ground_truths"],
        asr_results=batch_results_storage["asr_results"],
        matcher=matcher
    )

    if csv_path and os.path.exists(csv_path):
        count = len(batch_results_storage["file_names"])
        return csv_path, f"âœ… CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\n\nğŸ“Š ì´ {count}ê°œ íŒŒì¼ ì²˜ë¦¬\nğŸ“ íŒŒì¼: {csv_path}"
    else:
        return None, "âŒ CSV ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"

