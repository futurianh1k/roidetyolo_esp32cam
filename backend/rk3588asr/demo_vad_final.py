# -*- coding: utf-8 -*-
"""
Sherpa-ONNX Sense-Voice RKNN Speech Recognition Web UI for RK3588
Offline Recognizer + ì²­í¬ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (v4 - CSV ë¦¬í¬íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)

ğŸ”§ v4 ê°œì„  ì‚¬í•­:
1. ë§ˆì´í¬ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì„¸ì…˜ ê²°ê³¼ ëˆ„ì  ê¸°ëŠ¥
2. ë§ˆì´í¬ ì„¸ì…˜ìš© CSV ë¦¬í¬íŠ¸ ìë™ ìƒì„±
3. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ìš© CSV ë¦¬í¬íŠ¸ ìë™ ìƒì„±
4. UIì— CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
5. ì„¸ì…˜ë³„ ê²°ê³¼ ê´€ë¦¬ ë° ì´ˆê¸°í™” ê¸°ëŠ¥
"""

import os
import warnings
import gradio as gr
import numpy as np
from datetime import datetime
import soundfile as sf
import wave
import queue
import threading
import time
from collections import deque

# ìì²´ ì„œëª… ì¸ì¦ì„œ ì‚¬ìš© ì‹œ Gradio ë‚´ë¶€ API í˜¸ì¶œ SSL ê²€ì¦ ë¹„í™œì„±í™”
os.environ['GRADIO_SSL_VERIFY'] = 'false'
os.environ['CURL_CA_BUNDLE'] = ''
os.environ['REQUESTS_CA_BUNDLE'] = ''
os.environ['PYTHONHTTPSVERIFY'] = '0'
# httpx SSL ê²€ì¦ ë¹„í™œì„±í™” (ìì²´ ì„œëª… ì¸ì¦ì„œ ì‚¬ìš© ì‹œ)
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

# httpx í´ë¼ì´ì–¸íŠ¸ì˜ SSL ê²€ì¦ ë¹„í™œì„±í™”ë¥¼ ìœ„í•œ íŒ¨ì¹˜
try:
    import httpx
    # httpxì˜ ê¸°ë³¸ SSL ê²€ì¦ ë¹„í™œì„±í™”
    original_init = httpx.Client.__init__
    def patched_init(self, *args, verify=False, **kwargs):
        return original_init(self, *args, verify=False, **kwargs)
    httpx.Client.__init__ = patched_init
    
    original_async_init = httpx.AsyncClient.__init__
    def patched_async_init(self, *args, verify=False, **kwargs):
        return original_async_init(self, *args, verify=False, **kwargs)
    httpx.AsyncClient.__init__ = patched_async_init
except ImportError:
    pass

from difflib import SequenceMatcher
from typing import List, Tuple, Dict, Optional
import re
import json
import logging
import csv
import uuid
import requests

# jiwerëŠ” ì„ íƒì  ì˜ì¡´ì„±ìœ¼ë¡œ ì²˜ë¦¬
try:
    from jiwer import compute_measures
    JIWER_AVAILABLE = True
except ImportError:
    compute_measures = None
    JIWER_AVAILABLE = False
    print("[WARN] jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `pip install jiwer` ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")


warnings.filterwarnings("ignore")

# ====================
# ë¡œê¹… ì„¤ì •
# ====================
logging.basicConfig(
    level=logging.INFO,  # DEBUG ë ˆë²¨ë¡œ ì„¤ì •
    format='%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# sherpa-onnx import
try:
    import sherpa_onnx
except ImportError:
    raise ImportError(
        "sherpa-onnxë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:\n"
        "pip install sherpa-onnx -f https://k2-fsa.github.io/sherpa/onnx/rk-npu.html"
    )

# ====================
# ì „ì—­ ì„¤ì •
# ====================
MODEL_DIR = os.path.join(
    os.getcwd(),
    "models",
    "sherpa-onnx-rk3588-30-seconds-sense-voice-zh-en-ja-ko-yue-2024-07-17",
)

MODEL_PATH = os.path.join(MODEL_DIR, "model.rknn")
TOKENS_PATH = os.path.join(MODEL_DIR, "tokens.txt")

# ì „ì—­ recognizer ë³€ìˆ˜
recognizer = None

# ====================
# ğŸ”¹ ì‘ê¸‰ ìƒí™© API ì„¤ì •
# ====================
EMERGENCY_API_CONFIG = {
    "enabled": True,  # API í˜¸ì¶œ í™œì„±í™” ì—¬ë¶€
    "api_endpoints": [
        {
            "name": "Emergency Alert API (JSON)",
            "url": "http://10.10.11.23:10008/api/emergency/quick",
            "enabled": True,
            "method": "POST",
            "type": "json"
        },
        {
            "name": "Emergency Alert API (Multipart)",
            "url": "http://10.10.11.23:10008/api/emergency/quick/{watchId}",
            "enabled": True,
            "method": "POST",
            "type": "multipart"
        }
    ],
    "watch_id": "watch_1764653561585_7956",
    "sender_id": "voice_asr_system",
    "include_image_url": True,
    "image_base_url": "http://10.10.11.79:8080/api/images",
    "fcm_project_id": "emergency-alert-system-f27e6",
}


def send_emergency_alert(recognized_text: str, emergency_keywords: List[str]):
    """
    ì‘ê¸‰ ìƒí™© ê°ì§€ ì‹œ APIë¡œ ì´ë²¤íŠ¸ ì „ì†¡
    
    Args:
        recognized_text: ìŒì„± ì¸ì‹ ê²°ê³¼ í…ìŠ¤íŠ¸
        emergency_keywords: ê°ì§€ëœ ì‘ê¸‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    if not EMERGENCY_API_CONFIG.get("enabled", False):
        logger.info("âš ï¸ ì‘ê¸‰ API í˜¸ì¶œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return
    
    config = EMERGENCY_API_CONFIG
    enabled_endpoints = [ep for ep in config.get("api_endpoints", []) if ep.get("enabled", False)]
    
    if not enabled_endpoints:
        logger.warning("âš ï¸ í™œì„±í™”ëœ API ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # JSON íƒ€ì… API ìš°ì„  ì„ íƒ
    selected_api = None
    for ep in enabled_endpoints:
        if ep.get("type") == "json":
            selected_api = ep
            break
    
    if not selected_api and enabled_endpoints:
        selected_api = enabled_endpoints[0]
    
    if not selected_api:
        logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ API ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        logger.info(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€! API í˜¸ì¶œ ì‹œì‘: {selected_api['name']}")
        logger.info(f"   - ì¸ì‹ í…ìŠ¤íŠ¸: {recognized_text}")
        logger.info(f"   - ê°ì§€ í‚¤ì›Œë“œ: {', '.join(emergency_keywords)}")
        
        # ì´ë²¤íŠ¸ ë°ì´í„° ìƒì„±
        event_id = str(uuid.uuid4())
        timestamp = datetime.now().isoformat()
        watch_id = config.get("watch_id", "watch_default")
        sender_id = config.get("sender_id", "voice_asr_system")
        
        if selected_api.get("type") == "json":
            # JSON ë°©ì‹
            api_url = selected_api['url']
            if '{watchId}' in api_url:
                api_url = api_url.replace('{watchId}', watch_id)
            elif watch_id not in api_url:
                if not api_url.endswith('/'):
                    api_url += '/'
                api_url += watch_id
            
            # ì´ë¯¸ì§€ URL ìƒì„± (ì„ íƒì )
            image_url = None
            if config.get("include_image_url", False):
                image_base = config.get("image_base_url", "http://10.10.11.79:8080/api/images")
                image_filename = f"emergency_{event_id.split('-')[0]}.jpeg"
                image_url = f"{image_base}/{image_filename}"
            
            # ì„œë²„ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œë§Œ ë°ì´í„° êµ¬ì„±
            request_data = {
                "senderId": sender_id,
                "note": f"ì‘ê¸‰ ìƒí™© ê°ì§€: {recognized_text} (í‚¤ì›Œë“œ: {', '.join(emergency_keywords)})",
                "imageUrl": image_url  # null ê°€ëŠ¥
            }
            
            logger.info(f"ğŸ“¤ API ìš”ì²­ URL: {api_url}")
            logger.info(f"ğŸ“¤ ìš”ì²­ ë°ì´í„°: {request_data}")

            # âœ… ìˆ˜ì •: api_url ì‚¬ìš© ë° requests.post() ì‚¬ìš©
            response = requests.post(
                url=api_url,  # âœ… ìˆ˜ì •: api_url ì‚¬ìš©
                json=request_data,  # âœ… ìˆ˜ì •: ì„œë²„ê°€ ê¸°ëŒ€í•˜ëŠ” í•„ë“œë§Œ
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            logger.info(f"âœ… API í˜¸ì¶œ ì„±ê³µ (Status: {response.status_code})")
            logger.info(f"   - Event ID: {event_id}")
            logger.info(f"   - Response: {response.text[:200]}")
        
        else:
            # Multipart ë°©ì‹
            api_url = selected_api['url']
            if '{watchId}' in api_url:
                api_url = api_url.replace('{watchId}', watch_id)
            elif watch_id not in api_url:
                if not api_url.endswith('/'):
                    api_url += '/'
                api_url += watch_id
            
            # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ senderIdì™€ note ì¶”ê°€
            import urllib.parse
            note_text = f"ì‘ê¸‰ ìƒí™© ê°ì§€: {recognized_text} (í‚¤ì›Œë“œ: {', '.join(emergency_keywords)})"
            query_params = {
                'senderId': sender_id,
                'note': note_text
            }
            api_url_with_params = f"{api_url}?{urllib.parse.urlencode(query_params)}"
            
            # multipart/form-data í˜•ì‹ìœ¼ë¡œ ì „ì†¡ (imageëŠ” ë¹ˆ ê°’)
            files = {
                'image': ('', '')  # ë¹ˆ ì´ë¯¸ì§€ íŒŒì¼
            }
            
            logger.info(f"ğŸ“¤ API ìš”ì²­ URL: {api_url_with_params}")
            logger.info(f"ğŸ“¤ Multipart files: {files}")

            # âœ… ìˆ˜ì •: requests.post() ì‚¬ìš©
            response = requests.post(
                url=api_url_with_params,
                files=files,
                timeout=10
            )
            
            logger.info(f"âœ… API í˜¸ì¶œ ì„±ê³µ (Status: {response.status_code})")
            logger.info(f"   - Response: {response.text[:200]}")
    
    except requests.exceptions.Timeout:
        logger.error("âŒ API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
    
    except requests.exceptions.ConnectionError:
        logger.error("âŒ API ì—°ê²° ì˜¤ë¥˜")
    
    except Exception as e:
        logger.error(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

# ì–¸ì–´ ë§¤í•‘
LANGUAGE_MAP = {
    "ìë™ ê°ì§€": "auto",
    "í•œêµ­ì–´": "ko",
    "ì¤‘êµ­ì–´": "zh",
    "ì˜ì–´": "en",
    "ì¼ë³¸ì–´": "ja",
    "ê´‘ë™ì–´": "yue",
}

# ====================
# ì •ë‹µ ë°ì´í„° (Ground Truth)
# ====================
GROUND_TRUTHS = [
    # ì¼ìƒ ìƒí™© 10ê°œ
    "íšŒì˜ëŠ” ì˜¤í›„ ì„¸ ì‹œì— ì‹œì‘í•´ ì•Œë¦¼ ì„¤ì •í•´ ì¤˜",
    "ë‚´ì¼ ì•„ì¹¨ ì¼ê³± ì‹œì— ê¸°ìƒ ì•ŒëŒì„ ì¶”ê°€í•´",
    "ê±°ì‹¤ ë¶ˆ ë„ê³  ê³µê¸°ì²­ì •ê¸° ì•½í•˜ê²Œ ì¼œ",
    "ì˜¤ëŠ˜ ì ì‹¬ì€ ê¹€ì¹˜ë³¶ìŒë°¥ ë‘ ê°œ ì£¼ë¬¸í• ê¹Œ",
    "ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í° ë°°í„°ë¦¬ ì”ëŸ‰ ì–¼ë§ˆì•¼",
    "ì¼ì •ì— ê³ ê° ë¯¸íŒ… ì˜¤í›„ ë‘ ì‹œë¡œ ë“±ë¡í•´",
    "ì™€ì´íŒŒì´ê°€ ìê¾¸ ëŠê²¨ ì†ë„ í…ŒìŠ¤íŠ¸ í•´ë´",
    "ì˜ìˆ˜ì¦ ì‚¬ì§„ì„ ìŠ¤ìº”í•´ì„œ ì´ë©”ì¼ë¡œ ë³´ë‚´",
    "ì£¼ë§ì— ê°€ì¡± ì˜í™” ì¶”ì²œí•´ ì¤˜ ì•¡ì…˜ ë§ê³ ",
    "ë‚ ì”¨ ì–´ë•Œ ìš°ì‚° ì±™ê²¨ì•¼ í• ê¹Œ",
    # ì‘ê¸‰ ìƒí™© 10ê°œ
    "ë„ì™€ì¤˜ ì‚¬ëŒì´ ì“°ëŸ¬ì¡Œì–´",
    "119ì— ë°”ë¡œ ì‹ ê³ í•´ í˜¸í¡ì´ ë©ˆì¶˜ ê²ƒ ê°™ì•„",
    "ë¶ˆì´ì•¼ ì£¼ë°©ì—ì„œ ì—°ê¸°ê°€ ë‚˜",
    "ì‹¬ì¥ì´ ì•„íŒŒ ê°€ìŠ´ì´ ì¡°ì—¬ ì™€",
    "í° ì‚¬ê³ ì•¼ í”¼ê°€ ë§ì´ ë‚˜ ìœ„ì¹˜ ì „ì†¡í•´ ì¤˜",
    "ì•ŒëŸ¬ì§€ ë°˜ì‘ì´ì•¼ ìˆ¨ì‰¬ê¸° í˜ë“¤ì–´.",
    "ì–´ì§€ëŸ½ê³  êµ¬í† ê°€ ë‚˜ êµ¬ê¸‰ì°¨ í˜¸ì¶œí•´",
    "ë…¸ì•½ìê°€ ê³„ë‹¨ì—ì„œ ë„˜ì–´ì¡Œì–´ ì˜ì‹ì´ í¬ë¯¸í•´",
    "ê°€ìŠ¤ ëƒ„ìƒˆê°€ ì‹¬í•´ ì¦‰ì‹œ í™˜ê¸°í•˜ê³  ì‹ ê³ í•´",
    "ì•„ì´ ì²´ì˜¨ì´ 40ë„ì•¼ ì‘ê¸‰ì‹¤ ì•ˆë‚´í•´ ì¤˜",
]

LABELS = ["ì¼ìƒ"] * 10 + ["ì‘ê¸‰"] * 10


# ====================
# ğŸ”¹ ì„¸ì…˜ ê²°ê³¼ ì €ì¥ì†Œ (ë§ˆì´í¬ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ìš©)
# ====================
class MicrophoneSessionRecorder:
    """ë§ˆì´í¬ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì„¸ì…˜ ê²°ê³¼ë¥¼ ëˆ„ì  ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.sessions = []  # ê° ì„¸ì…˜ì˜ ê²°ê³¼ë¥¼ ì €ì¥
        self.current_session_id = 0
        self.lock = threading.Lock()

    def add_session_result(self, ground_truth: str, asr_result: str, duration: float, timestamp: str):
        """ì„¸ì…˜ ê²°ê³¼ ì¶”ê°€"""
        with self.lock:
            self.current_session_id += 1
            session_data = {
                "session_id": self.current_session_id,
                "timestamp": timestamp,
                "duration": duration,
                "ground_truth": ground_truth,
                "asr_result": asr_result,
            }
            self.sessions.append(session_data)
            logger.info(f"âœ… ì„¸ì…˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: Session #{self.current_session_id}")

    def get_all_sessions(self) -> List[Dict]:
        """ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ ë°˜í™˜"""
        with self.lock:
            return self.sessions.copy()

    def get_session_count(self) -> int:
        """ì €ì¥ëœ ì„¸ì…˜ ê°œìˆ˜ ë°˜í™˜"""
        with self.lock:
            return len(self.sessions)

    def clear_sessions(self):
        """ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ ì´ˆê¸°í™”"""
        with self.lock:
            self.sessions.clear()
            self.current_session_id = 0
            logger.info("ğŸ”„ ì„¸ì…˜ ê²°ê³¼ ì´ˆê¸°í™” ì™„ë£Œ")


# ì „ì—­ ì„¸ì…˜ ë ˆì½”ë”
mic_session_recorder = MicrophoneSessionRecorder()

# ğŸ”¹ VAD ì„¸ì…˜ ì±„íŒ… íˆìŠ¤í† ë¦¬ (ì‹¤ì‹œê°„ ëˆ„ì  í‘œì‹œìš©)
vad_chat_history = []


def clear_vad_chat_history():
    """VAD ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
    global vad_chat_history
    vad_chat_history = []
    logger.info("ğŸ—‘ï¸ VAD ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")


def add_to_vad_chat_history(timestamp: str, text: str, duration: float, is_emergency: bool = False, emergency_keywords: list = None):
    """VAD ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
    global vad_chat_history
    
    message = {
        'timestamp': timestamp,
        'text': text,
        'duration': duration,
        'is_emergency': is_emergency,
        'emergency_keywords': emergency_keywords or []
    }
    
    vad_chat_history.append(message)
    logger.debug(f"ğŸ“ ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶”ê°€: {len(vad_chat_history)}ê°œ")


def format_vad_chat_history() -> str:
    """VAD ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
    global vad_chat_history
    
    if not vad_chat_history:
        return "ğŸ‘‚ ëŒ€ê¸° ì¤‘... ë§ì”€í•´ì£¼ì„¸ìš”."
    
    formatted = "ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘...\n\n"
    formatted += f"ğŸ“Š ê°ì§€ëœ ìŒì„± êµ¬ê°„: {len(vad_chat_history)}ê°œ\n\n"
    formatted += "=" * 60 + "\n\n"
    
    for idx, msg in enumerate(vad_chat_history, 1):
        timestamp = msg['timestamp']
        text = msg['text']
        duration = msg['duration']
        is_emergency = msg['is_emergency']
        emergency_keywords = msg['emergency_keywords']
        
        # êµ¬ê°„ ë²ˆí˜¸ì™€ ì‹œê°„ í‘œì‹œ
        formatted += f"[{idx}] {timestamp} ({duration:.1f}ì´ˆ)\n"
        
        # ì‘ê¸‰ ìƒí™© í‘œì‹œ
        if is_emergency:
            formatted += f"ğŸš¨ ì‘ê¸‰: {text}\n"
            formatted += f"   í‚¤ì›Œë“œ: {', '.join(emergency_keywords)}\n"
        else:
            formatted += f"ğŸ’¬ {text}\n"
        
        formatted += "\n"
    
    formatted += "=" * 60 + "\n"
    formatted += "ğŸ‘‚ ê³„ì† ë“£ê³  ìˆìŠµë‹ˆë‹¤. ë§ì”€í•´ì£¼ì„¸ìš”..."
    
    return formatted


# ====================
# ğŸ”¹ CSV ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
# ====================
def generate_mic_session_csv_report(
    sessions: List[Dict],
    matcher,  # SpeechRecognitionMatcher ê°ì²´
    output_csv_path: str = None
) -> str:
    """
    ë§ˆì´í¬ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì„¸ì…˜ ê²°ê³¼ì— ëŒ€í•œ CSV ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        sessions: ì„¸ì…˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ê° dictëŠ” session_id, timestamp, duration, ground_truth, asr_result í¬í•¨)
        matcher: SpeechRecognitionMatcher ê°ì²´
        output_csv_path: ì €ì¥ë  CSV ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)

    Returns:
        ìƒì„±ëœ CSV íŒŒì¼ ê²½ë¡œ
    """

    if not sessions:
        logger.warning("âš ï¸ ìƒì„±í•  ì„¸ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ìë™ íŒŒì¼ëª… ìƒì„±
    if output_csv_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_csv_path = f"mic_session_cer_report_{timestamp}.csv"

    rows = []

    for session in sessions:
        session_id = session.get("session_id", "N/A")
        timestamp = session.get("timestamp", "N/A")
        duration = session.get("duration", 0.0)
        gt = session.get("ground_truth", "")
        asr = session.get("asr_result", "")

        # CER ì§ì ‘ ê³„ì‚°
        cer_direct = matcher.cer_direct(asr, gt)

        # jiwer CER ê³„ì‚°
        cer_jiwer_data = matcher.cer_jiwer(asr, gt)

        row = {
            "session_id": session_id,
            "timestamp": timestamp,
            "duration_sec": f"{duration:.2f}",
            "ground_truth": gt,
            "asr": asr,

            # ì§ì ‘ CER
            "cer_direct": f"{cer_direct['CER']:.4f}",
            "S_direct": cer_direct["S"],
            "D_direct": cer_direct["D"],
            "I_direct": cer_direct["I"],
            "N_direct": cer_direct["N"],
        }

        # jiwer CER ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        if cer_jiwer_data:
            row.update({
                "cer_jiwer": f"{cer_jiwer_data['CER']:.4f}",
                "S_jiwer": cer_jiwer_data["S"],
                "D_jiwer": cer_jiwer_data["D"],
                "I_jiwer": cer_jiwer_data["I"],
                "N_jiwer": cer_jiwer_data["N"],
            })
        else:
            row.update({
                "cer_jiwer": "",
                "S_jiwer": "",
                "D_jiwer": "",
                "I_jiwer": "",
                "N_jiwer": "",
            })

        rows.append(row)

    # CSV ì €ì¥
    header = [
        "session_id", "timestamp", "duration_sec", "ground_truth", "asr",
        "cer_direct", "S_direct", "D_direct", "I_direct", "N_direct",
        "cer_jiwer",  "S_jiwer", "D_jiwer", "I_jiwer", "N_jiwer"
    ]

    with open(output_csv_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()
        writer.writerows(rows)

    logger.info(f"[âœ”] ë§ˆì´í¬ ì„¸ì…˜ CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ â†’ {output_csv_path}")
    return output_csv_path


def generate_batch_csv_report(
    file_names: List[str],
    ground_truths: List[str],
    asr_results: List[str],
    matcher,  # SpeechRecognitionMatcher ê°ì²´
    output_csv_path: str = None
) -> str:
    """
    ë°°ì¹˜ íŒŒì¼ ìŒì„± ì¸ì‹ ê²°ê³¼ì— ëŒ€í•œ CSV ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        file_names: íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
        ground_truths: ì •ë‹µ(GT) ë¦¬ìŠ¤íŠ¸
        asr_results: ASR ì¸ì‹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        matcher: SpeechRecognitionMatcher ê°ì²´
        output_csv_path: ì €ì¥ë  CSV ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)

    Returns:
        ìƒì„±ëœ CSV íŒŒì¼ ê²½ë¡œ
    """

    assert len(ground_truths) == len(asr_results), "GTì™€ ASR ê°œìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤."
    if len(file_names) != len(ground_truths):
        # ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ìë™ ë²ˆí˜¸ ìƒì„±
        file_names = [f"audio_{i+1}.wav" for i in range(len(ground_truths))]

    # ìë™ íŒŒì¼ëª… ìƒì„±
    if output_csv_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_csv_path = f"batch_cer_report_{timestamp}.csv"

    rows = []

    for idx, (fname, gt, asr) in enumerate(zip(file_names, ground_truths, asr_results)):
        # CER ì§ì ‘ ê³„ì‚°
        cer_direct = matcher.cer_direct(asr, gt)

        # jiwer CER ê³„ì‚°
        cer_jiwer_data = matcher.cer_jiwer(asr, gt)

        row = {
            "file_name": fname,
            "ground_truth": gt,
            "asr": asr,

            # ì§ì ‘ CER
            "cer_direct": f"{cer_direct['CER']:.4f}",
            "S_direct": cer_direct["S"],
            "D_direct": cer_direct["D"],
            "I_direct": cer_direct["I"],
            "N_direct": cer_direct["N"],
        }

        # jiwer CER ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        if cer_jiwer_data:
            row.update({
                "cer_jiwer": f"{cer_jiwer_data['CER']:.4f}",
                "S_jiwer": cer_jiwer_data["S"],
                "D_jiwer": cer_jiwer_data["D"],
                "I_jiwer": cer_jiwer_data["I"],
                "N_jiwer": cer_jiwer_data["N"],
            })
        else:
            row.update({
                "cer_jiwer": "",
                "S_jiwer": "",
                "D_jiwer": "",
                "I_jiwer": "",
                "N_jiwer": "",
            })

        rows.append(row)

    # CSV ì €ì¥
    header = [
        "file_name", "ground_truth", "asr",
        "cer_direct", "S_direct", "D_direct", "I_direct", "N_direct",
        "cer_jiwer",  "S_jiwer", "D_jiwer", "I_jiwer", "N_jiwer"
    ]

    with open(output_csv_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()
        writer.writerows(rows)

    logger.info(f"[âœ”] ë°°ì¹˜ CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ â†’ {output_csv_path}")
    return output_csv_path


# ====================
# ë§¤ì¹­ ì‹œìŠ¤í…œ
# ====================
class SpeechRecognitionMatcher:
    """ìŒì„±ì¸ì‹ ê²°ê³¼ì™€ ì •ë‹µ ë¬¸ì¥ì„ ë¹„êµí•˜ëŠ” í´ë˜ìŠ¤"""

    EMERGENCY_KEYWORDS = [
        "ë„ì™€ì¤˜", "ì‚´ë ¤ì¤˜", "119", "ì‘ê¸‰", "ë¶ˆì´ì•¼", "í™”ì¬",
        "ì‹¬ì¥", "í˜¸í¡", "ì¶œí˜ˆ", "ì‚¬ê³ ", "êµ¬ê¸‰ì°¨", "ì‘ê¸‰ì‹¤",
        "ì•ŒëŸ¬ì§€", "êµ¬í† ", "ì˜ì‹", "ê°€ìŠ¤",
    ]

    def __init__(self, ground_truths: List[str], labels: List[str] = None):
        self.ground_truths = ground_truths
        self.labels = labels if labels else ["ì¼ìƒ"] * len(ground_truths)
        self.evaluation_results = []

    def preprocess(self, text: str) -> str:
        text = re.sub(r"\s+", " ", text)
        return text.strip()

    def calculate_similarity(self, text1: str, text2: str) -> float:
        return SequenceMatcher(None, text1, text2).ratio()

    def levenshtein_distance(self, s1: str, s2: str) -> int:
        if len(s1) < len(s2):
            return self.levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        return previous_row[-1]

    def character_accuracy(self, recognized: str, ground_truth: str) -> float:
        recognized = self.preprocess(recognized)
        ground_truth = self.preprocess(ground_truth)
        lev_dist = self.levenshtein_distance(recognized, ground_truth)
        max_len = max(len(recognized), len(ground_truth))
        if max_len == 0:
            return 1.0
        accuracy = 1.0 - (lev_dist / max_len)
        return max(0.0, accuracy)

    def detect_emergency_keywords(self, text: str) -> List[str]:
        detected = []
        text = self.preprocess(text)
        for keyword in self.EMERGENCY_KEYWORDS:
            if keyword in text:
                detected.append(keyword)
        return detected

    def find_best_match(self, recognized_text: str) -> Dict:
        recognized_text = self.preprocess(recognized_text)
        best_match = ""
        best_similarity = 0.0
        best_index = -1
        best_accuracy = 0.0

        for idx, ground_truth in enumerate(self.ground_truths):
            gt = self.preprocess(ground_truth)
            similarity = self.calculate_similarity(recognized_text, gt)
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = ground_truth
                best_index = idx
                best_accuracy = self.character_accuracy(recognized_text, ground_truth)

        emergency_keywords = self.detect_emergency_keywords(recognized_text)
        is_emergency = len(emergency_keywords) > 0


        # ğŸ”¹ best_matchì— ëŒ€í•´ CER ê³„ì‚°
        cer_direct = None
        cer_jiwer_result = None
        if best_match:
            cer_direct = self.cer_direct(recognized_text, best_match)
            cer_jiwer_result = self.cer_jiwer(recognized_text, best_match)

        result = {
            "recognized": recognized_text,
            "best_match": best_match,
            "similarity": best_similarity,
            "accuracy": best_accuracy,
            "index": best_index,
            "label": self.labels[best_index] if best_index >= 0 else "unknown",
            "emergency_keywords": emergency_keywords,
            "is_emergency": is_emergency,
            # ğŸ”¹ ì¶”ê°€ëœ í•„ë“œë“¤
            "cer": cer_direct["CER"] if cer_direct else None,  # CER ê°’ë§Œ í‘œì‹œ (0.xx í˜•ì‹)
            "cer_direct": cer_direct,         # ì „ì²´ ì •ë³´ (S, D, I, N í¬í•¨)
            "cer_jiwer": cer_jiwer_result["CER"] if cer_jiwer_result else None,  # jiwer CER ê°’ë§Œ
            "cer_jiwer_full": cer_jiwer_result,    # jiwer ê¸°ë°˜ ì „ì²´ ê²°ê³¼ (ë˜ëŠ” None)
        }
        self.evaluation_results.append(result)
        return result


    def reset_evaluation(self):
        self.evaluation_results = []

    # ============================
    # ğŸ”¹ (A) ì§ì ‘ êµ¬í˜„í•œ CER ê³„ì‚°
    # ============================
    def cer_direct(
        self,
        recognized: str,
        ground_truth: str,
        ignore_spaces: bool = True,
    ) -> Dict[str, float]:
        """
        ì§ì ‘ êµ¬í˜„í•œ Levenshtein DP + tracebackìœ¼ë¡œ CER ê³„ì‚°
        CER = (S + D + I) / N
          - N: ì •ë‹µ(GT) ì „ì²´ ìŒì ˆ ìˆ˜
          - S: ì¹˜í™˜(substitution) ê°œìˆ˜
          - D: ì‚­ì œ(deletion) ê°œìˆ˜
          - I: ì‚½ì…(insertion) ê°œìˆ˜
        """

        # ì „ì²˜ë¦¬
        rec = self.preprocess(recognized)
        gt = self.preprocess(ground_truth)

        if ignore_spaces:
            rec = rec.replace(" ", "")
            gt = gt.replace(" ", "")

        ref_chars = list(gt)   # ì •ë‹µ(GT)
        hyp_chars = list(rec)  # ì¸ì‹ ê²°ê³¼

        r = len(ref_chars)
        h = len(hyp_chars)

        # DP í…Œì´ë¸” ìƒì„±
        dp = [[0] * (h + 1) for _ in range(r + 1)]
        for i in range(r + 1):
            dp[i][0] = i   # ì‚­ì œ
        for j in range(h + 1):
            dp[0][j] = j   # ì‚½ì…

        # DP ì±„ìš°ê¸°
        for i in range(1, r + 1):
            for j in range(1, h + 1):
                cost = 0 if ref_chars[i - 1] == hyp_chars[j - 1] else 1
                dp[i][j] = min(
                    dp[i - 1][j] + 1,      # ì‚­ì œ D
                    dp[i][j - 1] + 1,      # ì‚½ì… I
                    dp[i - 1][j - 1] + cost,  # ì¹˜í™˜ S or ì¼ì¹˜(hit)
                )

        # traceback ìœ¼ë¡œ S, D, I ê³„ì‚°
        i, j = r, h
        S = D = I = 0

        while i > 0 or j > 0:
            # ì‚­ì œ
            if i > 0 and dp[i][j] == dp[i - 1][j] + 1:
                D += 1
                i -= 1
            # ì‚½ì…
            elif j > 0 and dp[i][j] == dp[i][j - 1] + 1:
                I += 1
                j -= 1
            else:
                # ëŒ€ê°ì„  ì´ë™: ì¹˜í™˜ ë˜ëŠ” ì¼ì¹˜
                if i > 0 and j > 0 and ref_chars[i - 1] != hyp_chars[j - 1]:
                    S += 1
                i -= 1
                j -= 1

        N = r  # ì •ë‹µ ê¸¸ì´
        cer = (S + D + I) / N if N > 0 else 0.0

        return {
            "CER": cer,
            "S": S,
            "D": D,
            "I": I,
            "N": N,
        }

    # ============================
    # ğŸ”¹ (B) jiwer ê¸°ë°˜ CER ê³„ì‚°
    # ============================
    def cer_jiwer(
        self,
        recognized: str,
        ground_truth: str,
        ignore_spaces: bool = True,
    ) -> Optional[Dict[str, float]]:
        """
        jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•œ CER ê³„ì‚°
        (jiwerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ None ë°˜í™˜)
        """

        if not JIWER_AVAILABLE:
            # jiwer ë¯¸ì„¤ì¹˜ ì‹œì—ëŠ” None ë°˜í™˜ (ë˜ëŠ” ì˜ˆì™¸ ë°œìƒì‹œì¼œë„ ë¨)
            logging.warning(
                "jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install jiwer` í›„ ì‚¬ìš©í•˜ì„¸ìš”."
            )
            return None

        def char_transform(s: str):
            s = self.preprocess(s)
            if ignore_spaces:
                s = s.replace(" ", "")
            return list(s)

        measures = compute_measures(
            truth=ground_truth,
            hypothesis=recognized,
            truth_transform=char_transform,
            hypothesis_transform=char_transform,
        )

        S = measures["substitutions"]
        D = measures["deletions"]
        I = measures["insertions"]
        N = measures["reference_length"]
        cer = (S + D + I) / N if N > 0 else 0.0

        return {
            "CER": cer,
            "S": S,
            "D": D,
            "I": I,
            "N": N,
            "raw_measures": measures,
        }


matcher = SpeechRecognitionMatcher(GROUND_TRUTHS, LABELS)


# ====================
# Streaming Processor with VAD (Voice Activity Detection)
# ====================
class VADStreamingProcessor:
    """ì—ë„ˆì§€ ê¸°ë°˜ ê°„ë‹¨í•œ VADë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ í”„ë¡œì„¸ì„œ"""

    def __init__(self, recognizer, sample_rate=16000, vad_enabled=True):
        self.recognizer = recognizer
        self.sample_rate = sample_rate
        
        # ê°„ë‹¨í•œ ì—ë„ˆì§€ ê¸°ë°˜ VAD ì„¤ì •
        self.vad_enabled = vad_enabled
        self.energy_threshold = 0.01  # ì—ë„ˆì§€ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
        self.silence_duration = 1.5  # ì¹¨ë¬µ íŒë‹¨ ì‹œê°„ (ì´ˆ)
        self.min_speech_duration = 0.5  # ìµœì†Œ ìŒì„± ê¸¸ì´ (ì´ˆ)
        
        # ìŒì„± ë²„í¼
        self.audio_buffer = deque()
        self.speech_segments = []  # ìŒì„± êµ¬ê°„ ì €ì¥
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_session_active = False  # ì„¸ì…˜ í™œì„±í™” ìƒíƒœ
        self.is_processing = False  # ìŒì„± ì²˜ë¦¬ ì¤‘
        self.silence_frames = 0  # ì¹¨ë¬µ í”„ë ˆì„ ì¹´ìš´í„°
        self.speech_frames = 0  # ìŒì„± í”„ë ˆì„ ì¹´ìš´í„°
        self.last_result = ""
        self.lock = threading.Lock()
        
        logger.info(f"âœ… VADStreamingProcessor ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - VAD: ì—ë„ˆì§€ ê¸°ë°˜ ê°„ë‹¨í•œ VAD")
        logger.info(f"   - ì—ë„ˆì§€ ì„ê³„ê°’: {self.energy_threshold}")
        logger.info(f"   - ì¹¨ë¬µ ê°ì§€: {self.silence_duration}ì´ˆ")

    def _calculate_energy(self, audio_chunk: np.ndarray) -> float:
        """ì˜¤ë””ì˜¤ ì²­í¬ì˜ ì—ë„ˆì§€ ê³„ì‚° (RMS)"""
        return np.sqrt(np.mean(audio_chunk ** 2))

    def _is_speech(self, audio_chunk: np.ndarray) -> bool:
        """ì—ë„ˆì§€ ê¸°ë°˜ ìŒì„± ê°ì§€"""
        if not self.vad_enabled:
            return True
        
        energy = self._calculate_energy(audio_chunk)
        return energy > self.energy_threshold

    def start_session(self):
        """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ (ë§ˆì´í¬ ê³„ì† ì¼œì§)"""
        with self.lock:
            if self.is_session_active:
                logger.warning("âš ï¸ ì´ë¯¸ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                return False
            
            self.is_session_active = True
            self.is_processing = False
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.last_result = ""
            self.silence_frames = 0
            self.speech_frames = 0
            
            logger.info("=" * 60)
            logger.info("ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘")
            logger.info("   - ë§ˆì´í¬ í™œì„±í™”: ê³„ì† ë“£ê¸° ëª¨ë“œ")
            logger.info("   - ì—ë„ˆì§€ ê¸°ë°˜ VADë¡œ ìŒì„± ìë™ ê°ì§€")
            logger.info("=" * 60)
            return True

    def stop_session(self):
        """ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ (ë§ˆì´í¬ ë”)"""
        with self.lock:
            if not self.is_session_active:
                logger.warning("âš ï¸ í™œì„±í™”ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            logger.info("â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")
            
            # ë‚¨ì€ ë²„í¼ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
            if len(self.audio_buffer) > 0 and self.is_processing:
                speech_audio = np.array(self.audio_buffer)
                duration = len(speech_audio) / self.sample_rate
                
                if duration >= self.min_speech_duration:
                    result = self._process_speech_segment(speech_audio)
                    if result:
                        self.speech_segments.append(result)
            
            self.is_session_active = False
            self.is_processing = False
            
            # ì„¸ì…˜ í†µê³„
            segment_count = len(self.speech_segments)
            total_duration = sum(seg.get('duration', 0) for seg in self.speech_segments)
            
            logger.info(f"ğŸ“Š ì„¸ì…˜ í†µê³„:")
            logger.info(f"   - ê°ì§€ëœ ìŒì„± êµ¬ê°„: {segment_count}ê°œ")
            logger.info(f"   - ì´ ìŒì„± ê¸¸ì´: {total_duration:.1f}ì´ˆ")
            
            result = {
                'segments': self.speech_segments.copy(),
                'total_segments': segment_count,
                'total_duration': total_duration
            }
            
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.silence_frames = 0
            self.speech_frames = 0
            
            return result

    def add_audio_chunk(self, audio_chunk: np.ndarray) -> Optional[Dict]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° VAD ê¸°ë°˜ ì²˜ë¦¬
        
        Returns:
            ìŒì„± ê°ì§€ ë° ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        with self.lock:
            if not self.is_session_active:
                return None
            
            try:
                # ìŒì„± í™œë™ ê°ì§€
                is_speech = self._is_speech(audio_chunk)
                
                if is_speech:
                    # ìŒì„±ì´ ê°ì§€ë˜ë©´
                    self.silence_frames = 0
                    self.speech_frames += 1
                    
                    if not self.is_processing:
                        # ìƒˆë¡œìš´ ìŒì„± êµ¬ê°„ ì‹œì‘
                        self.is_processing = True
                        self.audio_buffer.clear()
                        logger.info("ğŸ—£ï¸ ìŒì„± ê°ì§€ ì‹œì‘")
                    
                    self.audio_buffer.extend(audio_chunk)
                else:
                    # ì¹¨ë¬µì´ ê°ì§€ë˜ë©´
                    self.silence_frames += 1
                    
                    if self.is_processing:
                        # ìŒì„± ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° ë²„í¼ì— ì¶”ê°€ (ì§§ì€ ì¹¨ë¬µ í¬í•¨)
                        self.audio_buffer.extend(audio_chunk)
                        
                        # ì¹¨ë¬µ ì‹œê°„ ê³„ì‚°
                        silence_duration = (self.silence_frames * len(audio_chunk)) / self.sample_rate
                        
                        # ì¶©ë¶„í•œ ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ ìŒì„± êµ¬ê°„ ì²˜ë¦¬
                        if silence_duration >= self.silence_duration:
                            speech_audio = np.array(self.audio_buffer)
                            duration = len(speech_audio) / self.sample_rate
                            
                            if duration >= self.min_speech_duration:
                                result = self._process_speech_segment(speech_audio)
                                
                                if result:
                                    logger.info(f"âœ… ìŒì„± ì²˜ë¦¬ ì™„ë£Œ ({duration:.1f}ì´ˆ)")
                                    self.speech_segments.append(result)
                                    self.is_processing = False
                                    self.audio_buffer.clear()
                                    self.silence_frames = 0
                                    self.speech_frames = 0
                                    return result
                            else:
                                logger.debug(f"â­ï¸ ë„ˆë¬´ ì§§ì€ ìŒì„± ë¬´ì‹œ ({duration:.1f}ì´ˆ)")
                            
                            self.is_processing = False
                            self.audio_buffer.clear()
                            self.silence_frames = 0
                            self.speech_frames = 0
                
            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                return None
        
        return None

    def _process_speech_segment(self, audio_data: np.ndarray) -> Optional[Dict]:
        """ìŒì„± êµ¬ê°„ ì²˜ë¦¬ ë° ì¸ì‹"""
        try:
            duration = len(audio_data) / self.sample_rate
            
            # ìŒì„±ì¸ì‹ ìˆ˜í–‰
            stream = self.recognizer.create_stream()
            stream.accept_waveform(self.sample_rate, audio_data)
            self.recognizer.decode_stream(stream)
            result = stream.result
            
            text = result.text.strip()
            
            if text:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                segment_result = {
                    'timestamp': timestamp,
                    'text': text,
                    'duration': duration,
                    'confidence': 1.0  # Sherpa-ONNXëŠ” confidence scoreë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                }
                
                logger.info(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")
                self.last_result = text
                
                return segment_result
            else:
                logger.debug("ğŸ”‡ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
                return None
        
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def get_session_status(self) -> Dict:
        """í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            return {
                'is_active': self.is_session_active,
                'is_processing': self.is_processing,
                'segments_count': len(self.speech_segments),
                'last_result': self.last_result
            }

    def reset(self):
        """ì™„ì „ ì´ˆê¸°í™”"""
        with self.lock:
            logger.info("ğŸ”„ VADStreamingProcessor ì´ˆê¸°í™”")
            self.is_session_active = False
            self.is_processing = False
            self.audio_buffer.clear()
            self.speech_segments.clear()
            self.last_result = ""
            self.silence_frames = 0
            self.speech_frames = 0


# ê¸°ì¡´ StreamingProcessorëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
class StreamingProcessor:
    """Offline Recognizerë¥¼ ì‚¬ìš©í•œ ì²­í¬ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ë ˆê±°ì‹œ)"""

    def __init__(self, recognizer, sample_rate=16000, chunk_duration=20.0):
        self.recognizer = recognizer
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.chunk_size = int(sample_rate * chunk_duration)

        self.audio_buffer = deque()
        self.is_recording = False
        self.is_ready = False
        self.accumulated_audio = []
        self.last_result = ""
        self.lock = threading.Lock()

        logger.info(f"âœ… StreamingProcessor ì´ˆê¸°í™” (ì²­í¬ í¬ê¸°: {chunk_duration}ì´ˆ)")
        logger.debug(f"ì´ˆê¸° ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

    def prepare(self):
        """ë…¹ìŒ ì¤€ë¹„ (is_recordingì€ False ìœ ì§€)"""
        with self.lock:
            old_state = (self.is_ready, self.is_recording)

            self.is_ready = True
            self.is_recording = False
            self.audio_buffer.clear()
            self.accumulated_audio.clear()
            self.last_result = ""

            new_state = (self.is_ready, self.is_recording)

            logger.info("=" * 60)
            logger.info("ğŸŸ¡ ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ")
            logger.debug(f"ìƒíƒœ ë³€ê²½: {old_state} â†’ {new_state}")
            logger.debug(f"ë²„í¼ ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info("=" * 60)

    def start_recording(self):
        """ë…¹ìŒ ì‹œì‘ (ë§ˆì´í¬ í™œì„±í™” ì‹œ í˜¸ì¶œ)"""
        with self.lock:
            if not self.is_ready:
                logger.warning("âš ï¸ ì¤€ë¹„ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ë…¹ìŒ ì‹œì‘ ì‹œë„")
                logger.debug(f"í˜„ì¬ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")
                return False

            old_state = self.is_recording
            self.is_recording = True

            logger.info("=" * 60)
            logger.info("ğŸ”´ ë…¹ìŒ ì‹œì‘")
            logger.debug(f"is_recording: {old_state} â†’ {self.is_recording}")
            logger.info("=" * 60)
            return True

    def stop_recording(self):
        """ë…¹ìŒ ì¢…ë£Œ ë° ìµœì¢… ì²˜ë¦¬"""
        with self.lock:
            logger.info("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ìš”ì²­")
            logger.debug(f"í˜„ì¬ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

            if not self.is_recording:
                logger.warning("ë…¹ìŒ ì¤‘ì´ ì•„ë‹Œ ìƒíƒœì—ì„œ ì¢…ë£Œ ìš”ì²­")
                return None

            self.is_recording = False
            self.is_ready = False

            logger.debug(f"ìƒíƒœ ë³€ê²½: is_recording={True} â†’ {False}, is_ready={True} â†’ {False}")

            # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬
            if len(self.accumulated_audio) > 0:
                final_audio = np.concatenate(self.accumulated_audio)
                duration = len(final_audio) / self.sample_rate
                logger.info(f"ìµœì¢… ì˜¤ë””ì˜¤ ì²˜ë¦¬: {duration:.2f}ì´ˆ")

                result = self._process_audio(final_audio)
                logger.info(f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ - ìµœì¢… ê¸¸ì´: {duration:.2f}ì´ˆ")
                return result

            logger.warning("ëˆ„ì ëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŒ")
            return self.last_result

    def add_audio_chunk(self, audio_chunk: np.ndarray) -> Optional[str]:
        """ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° ì²˜ë¦¬"""
        # ğŸ”§ ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê°œì„ : ë½ ë²”ìœ„ ìµœì í™”
        with self.lock:
            # is_readyì´ë©´ì„œ is_recording=Falseì¸ ê²½ìš°: ì²« ì˜¤ë””ì˜¤ ë„ì°© ì‹œ ìë™ ì‹œì‘
            if self.is_ready and not self.is_recording:
                self.is_recording = True
                logger.info("ğŸ¤ ë§ˆì´í¬ í™œì„±í™” ê°ì§€ â†’ ìë™ ë…¹ìŒ ì‹œì‘")
                logger.debug(f"is_recording: False â†’ True (ìë™ ì „í™˜)")

            if not self.is_recording:
                logger.debug(f"ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ (is_ready={self.is_ready})")
                return None

            try:
                # ë²„í¼ì— ì¶”ê°€
                chunk_len = len(audio_chunk)
                self.audio_buffer.extend(audio_chunk)
                self.accumulated_audio.append(audio_chunk)

                logger.debug(f"ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€: {chunk_len} samples, ëˆ„ì : {len(self.accumulated_audio)} chunks")

                # ì²­í¬ í¬ê¸° ì¶©ì¡± ì‹œ ì²˜ë¦¬
                if len(self.audio_buffer) >= self.chunk_size:
                    logger.debug(f"ì²­í¬ í¬ê¸° ë„ë‹¬: {len(self.audio_buffer)} >= {self.chunk_size}")

                    # ì „ì²´ ëˆ„ì  ì˜¤ë””ì˜¤ë¡œ ì²˜ë¦¬ (ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸)
                    full_audio = np.concatenate(self.accumulated_audio)
                    result = self._process_audio(full_audio)

                    # ë²„í¼ ì¼ë¶€ë§Œ ìœ ì§€ (overlap)
                    overlap_size = self.chunk_size // 4
                    self.audio_buffer = deque(list(self.audio_buffer)[self.chunk_size - overlap_size:])

                    logger.debug(f"ë²„í¼ ì—…ë°ì´íŠ¸: overlap={overlap_size}, ë‚¨ì€ ë²„í¼={len(self.audio_buffer)}")

                    if result and result != self.last_result:
                        self.last_result = result
                        logger.info(f"ìƒˆë¡œìš´ ì¸ì‹ ê²°ê³¼: {result[:50]}...")
                        return result

            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ìƒíƒœ ì¼ê´€ì„± ìœ ì§€
                return None

        return None

    def _process_audio(self, audio_data: np.ndarray) -> str:
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬"""
        try:
            duration = len(audio_data) / self.sample_rate
            logger.debug(f"ìŒì„±ì¸ì‹ ì²˜ë¦¬ ì‹œì‘: {duration:.2f}ì´ˆ")

            if duration < 0.5:
                logger.debug("ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ 0.5ì´ˆ ë¯¸ë§Œ, ì²˜ë¦¬ ê±´ë„ˆëœ€")
                return ""

            # Offline Recognizerë¡œ ì²˜ë¦¬
            stream = self.recognizer.create_stream()
            stream.accept_waveform(self.sample_rate, audio_data)
            self.recognizer.decode_stream(stream)
            result = stream.result

            text = result.text.strip()
            logger.debug(f"ìŒì„±ì¸ì‹ ê²°ê³¼: '{text}'")
            return text

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            return ""

    def get_current_duration(self) -> float:
        """í˜„ì¬ ë…¹ìŒ ê¸¸ì´ ë°˜í™˜"""
        if len(self.accumulated_audio) > 0:
            total_samples = sum(len(chunk) for chunk in self.accumulated_audio)
            duration = total_samples / self.sample_rate
            logger.debug(f"í˜„ì¬ ë…¹ìŒ ê¸¸ì´: {duration:.2f}ì´ˆ ({len(self.accumulated_audio)} chunks)")
            return duration
        return 0.0

    def reset(self):
        """ì™„ì „ ì´ˆê¸°í™”"""
        with self.lock:
            logger.info("ğŸ”„ StreamingProcessor ì™„ì „ ì´ˆê¸°í™”")
            logger.debug(f"ì´ˆê¸°í™” ì „ ìƒíƒœ: is_ready={self.is_ready}, is_recording={self.is_recording}")

            self.is_recording = False
            self.is_ready = False
            self.audio_buffer.clear()
            self.accumulated_audio.clear()
            self.last_result = ""

            logger.debug("ì´ˆê¸°í™” ì™„ë£Œ: is_ready=False, is_recording=False, ë²„í¼ ë¹„ì›€")


# ì „ì—­ ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ (VAD ê¸°ë°˜)
vad_stream_processor: Optional[VADStreamingProcessor] = None
stream_processor: Optional[StreamingProcessor] = None


# ====================
# ëª¨ë¸ ë¡œë”©
# ====================
def load_model():
    """Offline Recognizer ë¡œë“œ"""
    global recognizer, vad_stream_processor

    logger.info("=" * 60)
    logger.info("ğŸ”„ Sherpa-ONNX Sense-Voice RKNN ëª¨ë¸ ë¡œë”© ì¤‘...")
    logger.info("ğŸ“¦ ëª¨ë¸: sense-voice (zh, en, ja, ko, yue)")
    logger.info("ğŸ–¥ï¸ í”Œë«í¼: RK3588 - NPU ìµœì í™”")
    logger.info("=" * 60)

    if not os.path.exists(MODEL_DIR):
        raise FileNotFoundError(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {MODEL_DIR}")

    required_files = {
        "RKNN Model": MODEL_PATH,
        "Tokens": TOKENS_PATH,
    }

    logger.info("ğŸ“ ëª¨ë¸ íŒŒì¼ í™•ì¸:")
    for name, path in required_files.items():
        if os.path.exists(path):
            size = os.path.getsize(path) / (1024**2)
            logger.info(f"  âœ… {name}: {os.path.basename(path)} ({size:.2f} MB)")
        else:
            raise FileNotFoundError(f"í•„ìˆ˜ íŒŒì¼ ì—†ìŒ: {name}")

    logger.info("âš™ï¸ Offline Recognizer ì´ˆê¸°í™” ì¤‘...")
    try:
        recognizer = sherpa_onnx.OfflineRecognizer.from_sense_voice(
            model=MODEL_PATH,
            tokens=TOKENS_PATH,
            num_threads=4,
            provider="rknn",
            use_itn=True,
            debug=False,
        )
        logger.info("âœ… Offline Recognizer ë¡œë”© ì™„ë£Œ!")

        # ğŸ”§ VAD ê¸°ë°˜ ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ ìƒì„±
        vad_stream_processor = VADStreamingProcessor(
            recognizer, 
            sample_rate=16000,
            vad_enabled=True  # VAD í™œì„±í™”
        )
        logger.info("âœ… VADStreamingProcessor ìƒì„± ì™„ë£Œ (VAD ì§€ì›)")

    except Exception as e:
        logger.error(f"âŒ Recognizer ë¡œë”© ì‹¤íŒ¨: {e}", exc_info=True)
        raise

    logger.info("=" * 60)
    logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    logger.info("=" * 60)


# ====================
# ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜
# ====================
def resample_audio(audio_data, orig_sr, target_sr=16000):
    """ì˜¤ë””ì˜¤ ë¦¬ìƒ˜í”Œë§"""
    if orig_sr == target_sr:
        return audio_data

    try:
        import librosa
        return librosa.resample(audio_data, orig_sr=orig_sr, target_sr=target_sr)
    except ImportError:
        from scipy import signal
        num_samples = int(len(audio_data) * target_sr / orig_sr)
        return signal.resample(audio_data, num_samples)


def read_wave(wave_filename: str):
    """Wave íŒŒì¼ ì½ê¸°"""
    with wave.open(wave_filename) as f:
        if f.getnchannels() != 1:
            raise ValueError(f"ëª¨ë…¸ ì˜¤ë””ì˜¤ë§Œ ì§€ì›. ì±„ë„: {f.getnchannels()}")
        if f.getsampwidth() != 2:
            raise ValueError(f"16ë¹„íŠ¸ ì˜¤ë””ì˜¤ë§Œ ì§€ì›. ìƒ˜í”Œí­: {f.getsampwidth()}")

        num_samples = f.getnframes()
        samples = f.readframes(num_samples)
        samples_int16 = np.frombuffer(samples, dtype=np.int16)
        samples_float32 = samples_int16.astype(np.float32) / 32768.0
        return samples_float32, f.getframerate()


# ====================
# ğŸ”¹ ë§ˆì´í¬ ì„¸ì…˜ ê´€ë ¨ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ (VAD ê¸°ë°˜)
# ====================
def start_vad_session_handler():
    """
    ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ í•¸ë“¤ëŸ¬ (VAD ê¸°ë°˜)
    
    - ë§ˆì´í¬ ê³„ì† ì¼œì§
    - VADë¡œ ìŒì„± ìë™ ê°ì§€
    - ìŒì„± ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ ASR-STT ìˆ˜í–‰
    """
    global vad_stream_processor

    logger.info("=" * 60)
    logger.info("ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ ìš”ì²­")

    if vad_stream_processor is None:
        logger.error("VADStreamingProcessorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ìŒì„±ì¸ì‹ ì‹œì‘"),
            gr.update(interactive=False),
            None,
            "âŒ ì˜¤ë¥˜: ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        ]
    
    # ì„¸ì…˜ ì‹œì‘
    success = vad_stream_processor.start_session()
    
    if success:
        session_count = mic_session_recorder.get_session_count()
        status_msg = (
            "ğŸ¤ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™”!\n\n"
            "âœ… ë§ˆì´í¬ê°€ ê³„ì† ì¼œì ¸ ìˆìŠµë‹ˆë‹¤.\n"
            "âœ… ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n"
            "âœ… VADê°€ ìŒì„±ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤.\n\n"
            "ğŸ”´ ìŒì„±ì¸ì‹ ì¢…ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„¸ì…˜ì„ ì¢…ë£Œí•˜ì„¸ìš”.\n\n"
            f"ğŸ“Š ì´ì „ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
        )
        
        logger.info("âœ… ìŒì„±ì¸ì‹ ì„¸ì…˜ ì‹œì‘ ì„±ê³µ")
        logger.info("=" * 60)
        
        return [
            gr.update(interactive=False, value="ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘..."),
            gr.update(interactive=True),
            None,
            status_msg
        ]
    else:
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ìŒì„±ì¸ì‹ ì‹œì‘"),
            gr.update(interactive=False),
            None,
            "âš ï¸ ì„¸ì…˜ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        ]


def stop_vad_session_handler(ground_truth_input):
    """
    ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ í•¸ë“¤ëŸ¬ (VAD ê¸°ë°˜)
    
    - ì„¸ì…˜ ì¢…ë£Œ
    - ê°ì§€ëœ ëª¨ë“  ìŒì„± êµ¬ê°„ ê²°ê³¼ í‘œì‹œ
    """
    global vad_stream_processor

    logger.info("â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")

    if vad_stream_processor is None:
        logger.error("VADStreamingProcessorê°€ None")
        return [
            "âš ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.",
            ""
        ]

    # ì„¸ì…˜ ì¢…ë£Œ
    session_result = vad_stream_processor.stop_session()
    
    if session_result:
        segments = session_result.get('segments', [])
        total_segments = session_result.get('total_segments', 0)
        total_duration = session_result.get('total_duration', 0)
        
        # ê° êµ¬ê°„ì— ëŒ€í•œ ì‘ê¸‰ ìƒí™© ì²´í¬
        emergency_detected = False
        emergency_segments = []
        
        result_text = f"â¹ï¸ ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ\n\n"
        result_text += f"ğŸ“Š ì„¸ì…˜ í†µê³„:\n"
        result_text += f"   - ê°ì§€ëœ ìŒì„± êµ¬ê°„: {total_segments}ê°œ\n"
        result_text += f"   - ì´ ìŒì„± ê¸¸ì´: {total_duration:.1f}ì´ˆ\n\n"
        
        if segments:
            result_text += "ğŸ“ ì¸ì‹ ê²°ê³¼:\n"
            result_text += "=" * 60 + "\n\n"
            
            for idx, seg in enumerate(segments, 1):
                text = seg.get('text', '')
                timestamp = seg.get('timestamp', '')
                duration = seg.get('duration', 0)
                
                result_text += f"[{idx}] {timestamp} ({duration:.1f}ì´ˆ)\n"
                result_text += f"    {text}\n\n"
                
                # ğŸš¨ ì‘ê¸‰ ìƒí™© ì²´í¬
                match_result = matcher.find_best_match(text)
                if match_result.get("is_emergency", False):
                    emergency_detected = True
                    emergency_keywords = match_result.get("emergency_keywords", [])
                    emergency_segments.append({
                        'index': idx,
                        'text': text,
                        'keywords': emergency_keywords,
                        'timestamp': timestamp
                    })
                    
                    logger.warning(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ [êµ¬ê°„ {idx}]: {emergency_keywords}")
                    
                    # API í˜¸ì¶œ (ì‹¤ì‹œê°„ì— ì´ë¯¸ í˜¸ì¶œë˜ì—ˆì§€ë§Œ ë‹¤ì‹œ í™•ì¸)
                    # send_emergency_alert(text, emergency_keywords)
        else:
            result_text += "âš ï¸ ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.\n"
        
        # ì‘ê¸‰ ìƒí™© ìš”ì•½
        if emergency_detected:
            result_text += "\n" + "=" * 60 + "\n"
            result_text += "ğŸš¨ğŸš¨ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! ğŸš¨ğŸš¨ğŸš¨\n\n"
            for emerg in emergency_segments:
                result_text += f"[êµ¬ê°„ {emerg['index']}] {emerg['timestamp']}\n"
                result_text += f"   í‚¤ì›Œë“œ: {', '.join(emerg['keywords'])}\n"
                result_text += f"   ë‚´ìš©: {emerg['text']}\n\n"
            result_text += "âœ… ì‘ê¸‰ ì•Œë¦¼ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        
        # ì„¸ì…˜ ê²°ê³¼ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹¨)
        if segments:
            combined_text = " ".join([seg.get('text', '') for seg in segments])
            gt = ground_truth_input.strip() if ground_truth_input else "(ì •ë‹µ ë¯¸ì…ë ¥)"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            mic_session_recorder.add_session_result(
                ground_truth=gt,
                asr_result=combined_text,
                duration=total_duration,
                timestamp=timestamp
            )
        
        session_count = mic_session_recorder.get_session_count()
        result_text += f"\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        clear_vad_chat_history()
        
        logger.info("âœ… ìŒì„±ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ ì™„ë£Œ")
        
        return [
            result_text,
            ""  # ground_truth ì´ˆê¸°í™”
        ]
    else:
        session_count = mic_session_recorder.get_session_count()
        clear_vad_chat_history()  # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        
        return [
            f"â¹ï¸ ì„¸ì…˜ ì¢…ë£Œ\n\nâš ï¸ í™œì„±í™”ëœ ì„¸ì…˜ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""
        ]


# ë ˆê±°ì‹œ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
def start_recording_handler():
    """
    ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í•¸ë“¤ëŸ¬ (ë ˆê±°ì‹œ)
    
    ğŸ”§ v4 ê°œì„ :
    - ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš© (ë§¤ë²ˆ ìƒì„±í•˜ì§€ ì•ŠìŒ)
    - prepare()ë¡œ ìƒíƒœ ì´ˆê¸°í™”
    """
    global stream_processor

    logger.info("=" * 60)
    logger.info("ğŸŸ¡ ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í´ë¦­")

    # ğŸ”§ v4: ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
    if stream_processor is not None:
        logger.debug("ê¸°ì¡´ StreamingProcessor ì¬ì‚¬ìš©")
        stream_processor.prepare()
    else:
        # ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ìƒì„± (ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ)
        logger.warning("StreamingProcessorê°€ None, ìƒˆë¡œ ìƒì„±")
        stream_processor = StreamingProcessor(recognizer, chunk_duration=20.0)
        stream_processor.prepare()

    logger.info(f"âœ… ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ: is_ready={stream_processor.is_ready}, is_recording={stream_processor.is_recording}")
    logger.info("=" * 60)

    # í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜ ê°œìˆ˜ í‘œì‹œ
    session_count = mic_session_recorder.get_session_count()
    status_msg = f"ğŸŸ¡ ì¤€ë¹„ ì™„ë£Œ!\n\në§ˆì´í¬ ë²„íŠ¼(ğŸ¤)ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”.\n2ì´ˆë§ˆë‹¤ ì‹¤ì‹œê°„ ì¸ì‹ë©ë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"

    return [
        gr.update(interactive=False, value="ğŸŸ¡ ì¤€ë¹„ ì™„ë£Œ - ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"),
        gr.update(interactive=True),
        None,  # Audio ì»´í¬ë„ŒíŠ¸ ë¦¬ì…‹
        status_msg
    ]


def stop_recording_handler(ground_truth_input):
    """
    ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ í•¸ë“¤ëŸ¬

    ğŸ”§ v4 ê°œì„ :
    - ì •ë‹µ(Ground Truth) ì…ë ¥ ë°›ì•„ì„œ ì„¸ì…˜ ê²°ê³¼ ì €ì¥
    """
    global stream_processor

    logger.info("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ í´ë¦­")

    if stream_processor is None:
        logger.error("StreamingProcessorê°€ None")
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            "âš ï¸ ë…¹ìŒ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.",
            ""  # ground_truth ì´ˆê¸°í™”
        ]

    logger.debug(f"ì¢…ë£Œ ì „ ìƒíƒœ: is_ready={stream_processor.is_ready}, is_recording={stream_processor.is_recording}")

    # is_readyë§Œ Trueì´ê³  is_recordingì´ Falseì¸ ê²½ìš° (ë§ˆì´í¬ë¥¼ ëˆ„ë¥´ì§€ ì•Šì€ ê²½ìš°)
    if stream_processor.is_ready and not stream_processor.is_recording:
        logger.warning("ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì€ ìƒíƒœì—ì„œ ì¢…ë£Œ")
        stream_processor.reset()
        session_count = mic_session_recorder.get_session_count()
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"âš ï¸ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì•„ ë…¹ìŒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]

    # ì •ìƒ ë…¹ìŒ ì¢…ë£Œ
    final_text = stream_processor.stop_recording()
    duration = stream_processor.get_current_duration()

    if final_text:
        # ğŸ”¹ ì„¸ì…˜ ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        gt = ground_truth_input.strip() if ground_truth_input else "(ì •ë‹µ ë¯¸ì…ë ¥)"

        mic_session_recorder.add_session_result(
            ground_truth=gt,
            asr_result=final_text,
            duration=duration,
            timestamp=timestamp
        )

        match_result = matcher.find_best_match(final_text)
        logger.info(f"â¹ï¸ ìµœì¢… ê²°ê³¼ ({duration:.1f}ì´ˆ): {match_result}")

        # ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ ì‹œ API í˜¸ì¶œ
        if match_result.get("is_emergency", False):
            emergency_keywords = match_result.get("emergency_keywords", [])
            logger.warning(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! í‚¤ì›Œë“œ: {emergency_keywords}")
            send_emergency_alert(final_text, emergency_keywords)

        session_count = mic_session_recorder.get_session_count()

        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ({duration:.1f}ì´ˆ)\n\nâœ… ìµœì¢… ê²°ê³¼:\n{final_text}\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]
    else:
        logger.warning("ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ")
        session_count = mic_session_recorder.get_session_count()
        return [
            gr.update(interactive=True, value="ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"),
            gr.update(interactive=False),
            f"â¹ï¸ ë…¹ìŒ ì¢…ë£Œ\n\nâš ï¸ ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ“Š í˜„ì¬ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
            ""  # ground_truth ì´ˆê¸°í™”
        ]


def generate_mic_csv_handler():
    """ë§ˆì´í¬ ì„¸ì…˜ CSV ë¦¬í¬íŠ¸ ìƒì„± í•¸ë“¤ëŸ¬"""
    sessions = mic_session_recorder.get_all_sessions()

    if not sessions:
        return None, "âš ï¸ ìƒì„±í•  ì„¸ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë…¹ìŒ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”."

    # CSV ìƒì„±
    csv_path = generate_mic_session_csv_report(sessions, matcher)

    if csv_path and os.path.exists(csv_path):
        return csv_path, f"âœ… CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\n\nğŸ“Š ì´ {len(sessions)}ê°œ ì„¸ì…˜ ì²˜ë¦¬\nğŸ“ íŒŒì¼: {csv_path}"
    else:
        return None, "âŒ CSV ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"


def clear_mic_sessions_handler():
    """ë§ˆì´í¬ ì„¸ì…˜ ê²°ê³¼ ì´ˆê¸°í™” í•¸ë“¤ëŸ¬"""
    mic_session_recorder.clear_sessions()
    return "âœ… ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”."


def auto_start_vad_session():
    """
    ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ VAD ì„¸ì…˜ í™œì„±í™”
    """
    global vad_stream_processor

    logger.info("ğŸ¤ ë§ˆì´í¬ í™œì„±í™” ê°ì§€ - ìë™ìœ¼ë¡œ VAD ì„¸ì…˜ ì‹œì‘")

    if vad_stream_processor is None:
        logger.error("VADStreamingProcessorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return "âŒ ì˜¤ë¥˜: ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ê¸°ì¡´ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¦¬ì…‹
    if vad_stream_processor.get_session_status()['is_active']:
        vad_stream_processor.reset()
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    clear_vad_chat_history()
    
    # ì„¸ì…˜ ì‹œì‘
    success = vad_stream_processor.start_session()
    
    if success:
        session_count = mic_session_recorder.get_session_count()
        return (
            "ğŸ¤ ìŒì„±ì¸ì‹ ì‹œì‘!\n\n"
            "âœ… ë§ˆì´í¬ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            "âœ… ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n"
            "âœ… VADê°€ ìŒì„±ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤.\n\n"
            "ğŸ—£ï¸ ì§€ê¸ˆ ë§ì”€í•´ì£¼ì„¸ìš”...\n\n"
            f"ğŸ“Š ì´ì „ ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
        )
    else:
        return "âš ï¸ ì„¸ì…˜ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def reset_vad_session_handler():
    """
    VAD ì„¸ì…˜ ë¦¬ì…‹ í•¸ë“¤ëŸ¬
    """
    global vad_stream_processor

    logger.info("ğŸ”„ VAD ì„¸ì…˜ ë¦¬ì…‹ ìš”ì²­")

    if vad_stream_processor is None:
        return [
            None,
            "âš ï¸ ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            ""
        ]
    
    vad_stream_processor.reset()
    clear_vad_chat_history()  # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    session_count = mic_session_recorder.get_session_count()
    
    return [
        None,  # audio ì»´í¬ë„ŒíŠ¸ ë¦¬ì…‹
        f"ğŸ”„ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në§ˆì´í¬ ë²„íŠ¼ì„ ë‹¤ì‹œ í´ë¦­í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.\n\nğŸ“Š ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ",
        ""  # ground_truth ì´ˆê¸°í™”
    ]


def process_vad_audio_stream(audio_stream, language):
    """
    VAD ê¸°ë°˜ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬
    
    - ìë™ìœ¼ë¡œ ì„¸ì…˜ ì‹œì‘
    - VADë¡œ ìŒì„± ìë™ ê°ì§€
    - ìŒì„± ê°ì§€ ì‹œ ìë™ ASR-STT
    - ì±„íŒ… íˆìŠ¤í† ë¦¬ ëˆ„ì  í‘œì‹œ
    """
    global vad_stream_processor

    if audio_stream is None:
        yield ""
        return

    try:
        sr, audio_data = audio_stream

        if audio_data is None or len(audio_data) == 0:
            yield ""
            return

        # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)

        # float32 ì •ê·œí™”
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        elif audio_data.dtype == np.int32:
            audio_data = audio_data.astype(np.float32) / 2147483648.0
        elif audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            audio_data = resample_audio(audio_data, sr, 16000)

        # í”„ë¡œì„¸ì„œ í™•ì¸
        if not vad_stream_processor:
            yield ""
            return

        # ì„¸ì…˜ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ ì‹œì‘
        status = vad_stream_processor.get_session_status()
        if not status['is_active']:
            logger.info("ğŸ¤ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê°ì§€ - ìë™ìœ¼ë¡œ ì„¸ì…˜ ì‹œì‘")
            vad_stream_processor.start_session()
            clear_vad_chat_history()  # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            
            session_count = mic_session_recorder.get_session_count()
            yield (
                "ğŸ¤ ìŒì„±ì¸ì‹ ìë™ ì‹œì‘!\n\n"
                "âœ… ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n\n"
                "ğŸ—£ï¸ ì§€ê¸ˆ ë§ì”€í•´ì£¼ì„¸ìš”...\n\n"
                f"ğŸ“Š ì €ì¥ëœ ì„¸ì…˜: {session_count}ê°œ"
            )
            status = vad_stream_processor.get_session_status()

        # ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ (VAD ê¸°ë°˜)
        result = vad_stream_processor.add_audio_chunk(audio_data)
        
        segments_count = status['segments_count']
        is_processing = status['is_processing']
        
        if result:
            # ìƒˆë¡œìš´ ìŒì„± êµ¬ê°„ ì¸ì‹ ì™„ë£Œ
            text = result.get('text', '')
            duration = result.get('duration', 0)
            timestamp = result.get('timestamp', '')
            
            # ğŸš¨ ì‘ê¸‰ ìƒí™© ì‹¤ì‹œê°„ ì²´í¬
            match_result = matcher.find_best_match(text)
            is_emergency = False
            emergency_keywords = []
            
            if match_result.get("is_emergency", False):
                is_emergency = True
                emergency_keywords = match_result.get("emergency_keywords", [])
                logger.warning(f"ğŸš¨ ì‹¤ì‹œê°„ ì‘ê¸‰ ìƒí™© ê°ì§€! í‚¤ì›Œë“œ: {emergency_keywords}")
                
                # API í˜¸ì¶œ
                send_emergency_alert(text, emergency_keywords)
            
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            add_to_vad_chat_history(timestamp, text, duration, is_emergency, emergency_keywords)
            
            # ëˆ„ì ëœ íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥
            output = format_vad_chat_history()
            
            logger.info(f"ğŸ¤ VAD ì¸ì‹ ì™„ë£Œ: {text}")
            yield output
        else:
            # ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜ ëŒ€ê¸° ì¤‘ì¼ ë•Œ
            # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ
            if len(vad_chat_history) > 0:
                output = format_vad_chat_history()
                
                # ì²˜ë¦¬ ì¤‘ ìƒíƒœ ì¶”ê°€
                if is_processing:
                    output += "\n\nğŸ—£ï¸ ìŒì„± ê°ì§€ ì¤‘... ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤."
                
                yield output
            else:
                # íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ëŒ€ê¸° ë©”ì‹œì§€
                if is_processing:
                    yield (
                        "ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘...\n\n"
                        "ğŸ—£ï¸ ìŒì„± ê°ì§€ ì¤‘... ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤."
                    )
                else:
                    yield (
                        "ğŸ”´ ìŒì„±ì¸ì‹ ì„¸ì…˜ í™œì„±í™” ì¤‘...\n\n"
                        "ğŸ‘‚ ëŒ€ê¸° ì¤‘... ë§ì”€í•´ì£¼ì„¸ìš”."
                    )

    except Exception as e:
        logger.error(f"âŒ VAD ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        yield f"âŒ ì˜¤ë¥˜: {str(e)}"


def collect_and_process_audio(audio_stream, language):
    """
    ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ìˆ˜ì§‘ ë° ì‹¤ì‹œê°„ ì²˜ë¦¬ (ë ˆê±°ì‹œ)
    """
    global stream_processor

    if audio_stream is None:
        yield ""
        return

    try:
        sr, audio_data = audio_stream

        if audio_data is None or len(audio_data) == 0:
            yield ""
            return

        logger.debug(f"ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} samples, {sr}Hz")

        # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
            logger.debug("ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜")

        # float32 ì •ê·œí™”
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        elif audio_data.dtype == np.int32:
            audio_data = audio_data.astype(np.float32) / 2147483648.0
        elif audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            audio_data = resample_audio(audio_data, sr, 16000)
            logger.debug(f"ë¦¬ìƒ˜í”Œë§: {sr}Hz â†’ 16000Hz")

        # í”„ë¡œì„¸ì„œ ì¤€ë¹„ í™•ì¸
        if not stream_processor or not stream_processor.is_ready:
            logger.debug(f"í”„ë¡œì„¸ì„œ ì¤€ë¹„ ì•ˆ ë¨: stream_processor={stream_processor is not None}, is_ready={stream_processor.is_ready if stream_processor else 'N/A'}")
            yield ""
            return

        # ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
        result_text = stream_processor.add_audio_chunk(audio_data)
        duration = stream_processor.get_current_duration()

        if result_text:
            match_result = matcher.find_best_match(result_text)
            logger.info(f"ğŸ¤ ì‹¤ì‹œê°„ ì¸ì‹ ({duration:.1f}ì´ˆ): {match_result}")
            
            # ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ ì‹œ API í˜¸ì¶œ
            if match_result.get("is_emergency", False):
                emergency_keywords = match_result.get("emergency_keywords", [])
                logger.warning(f"ğŸš¨ ì‹¤ì‹œê°„ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨! í‚¤ì›Œë“œ: {emergency_keywords}")
                send_emergency_alert(result_text, emergency_keywords)
            
            yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nâœ… ì‹¤ì‹œê°„ ì¸ì‹:\n{result_text}"
        else:
            last = stream_processor.last_result
            if last:
                yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nâœ… í˜„ì¬ ì¸ì‹:\n{last}"
            else:
                if stream_processor.is_recording:
                    yield f"ğŸ”´ ë…¹ìŒ ì¤‘... ({duration:.1f}ì´ˆ)\n\nëŒ€ê¸° ì¤‘..."
                else:
                    yield ""

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        yield f"âŒ ì˜¤ë¥˜: {str(e)}"


# ====================
# íŒŒì¼ ì—…ë¡œë“œ ìŒì„±ì¸ì‹
# ====================
def _resolve_file_path(audio_file):
    """íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ"""
    if isinstance(audio_file, dict):
        return audio_file.get("path") or audio_file.get("name")
    if hasattr(audio_file, "name"):
        return audio_file.name
    return audio_file


def transcribe_file(audio_file, language):
    """íŒŒì¼ ì—…ë¡œë“œ ìŒì„±ì¸ì‹"""
    start_time = time.time()

    try:
        if audio_file is None:
            return "âš ï¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        file_path = _resolve_file_path(audio_file)
        if not file_path or not os.path.exists(file_path):
            return f"âŒ íŒŒì¼ ê²½ë¡œ ì˜¤ë¥˜: {file_path}"

        logger.info(f"â±ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")

        # íŒŒì¼ ì½ê¸°
        try:
            audio_data, sr = sf.read(file_path)
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)
            samples = audio_data.astype(np.float32)
            sample_rate = sr
        except Exception as e1:
            logger.warning(f"soundfile ì‹¤íŒ¨: {e1}, wave ì‹œë„")
            try:
                samples, sample_rate = read_wave(file_path)
            except Exception as e2:
                raise Exception(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨. soundfile: {e1}, wave: {e2}")

        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sample_rate != 16000:
            logger.info(f"ğŸ”„ ë¦¬ìƒ˜í”Œë§: {sample_rate} Hz â†’ 16000 Hz")
            samples = resample_audio(samples, sample_rate, 16000)
            sample_rate = 16000

        duration = len(samples) / sample_rate
        logger.info(f"ğŸ¤ ìŒì„±ì¸ì‹ ì‹œì‘ - ê¸¸ì´: {duration:.2f}ì´ˆ")

        # Offline Recognizerë¡œ ì²˜ë¦¬
        stream = recognizer.create_stream()
        stream.accept_waveform(sample_rate, samples)
        recognizer.decode_stream(stream)
        result = stream.result

        text = result.text.strip()

        # ì •ë‹µ ë§¤ì¹­
        match_result = matcher.find_best_match(text)

        if not text:
            text = "âš ï¸ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        file_name = os.path.basename(file_path)
        logger.info(f"ğŸ“ {file_name}\n{match_result}\n")

        total_time = time.time() - start_time
        logger.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {text}")
        logger.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")

        return text

    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        return f"âŒ ì˜¤ë¥˜: {str(e)}"


# ====================
# ğŸ”¹ ë°°ì¹˜ ì²˜ë¦¬ (CSV ìƒì„± ê¸°ëŠ¥ í†µí•©)
# ====================
# ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ì†Œ
batch_results_storage = {
    "file_names": [],
    "ground_truths": [],
    "asr_results": []
}


def batch_transcribe(files, language):
    """ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬"""
    global batch_results_storage

    if not files:
        return "âš ï¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    # ê²°ê³¼ ì´ˆê¸°í™”
    batch_results_storage = {
        "file_names": [],
        "ground_truths": [],
        "asr_results": []
    }

    results = []
    total = len(files)

    for idx, file in enumerate(files, 1):
        try:
            file_path = _resolve_file_path(file)
            file_name = os.path.basename(file_path)
            logger.info(f"[{idx}/{total}] ì²˜ë¦¬ ì¤‘: {file_name}")

            # íŒŒì¼ ì½ê¸°
            try:
                audio_data, sr = sf.read(file_path)
                if len(audio_data.shape) > 1:
                    audio_data = np.mean(audio_data, axis=1)
                samples = audio_data.astype(np.float32)
                sample_rate = sr
            except Exception:
                try:
                    samples, sample_rate = read_wave(file_path)
                except Exception as e:
                    raise Exception(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

            if sample_rate != 16000:
                samples = resample_audio(samples, sample_rate, 16000)
                sample_rate = 16000

            # Offline ì²˜ë¦¬
            stream = recognizer.create_stream()
            stream.accept_waveform(sample_rate, samples)
            recognizer.decode_stream(stream)
            result = stream.result
            text = result.text.strip()

            # ì •ë‹µ ë§¤ì¹­
            match_result = matcher.find_best_match(text)
            best_match = match_result.get("best_match", "")

            if not text:
                text = "(ìŒì„± ì¸ì‹ ì‹¤íŒ¨)"

            # ê²°ê³¼ ì €ì¥
            batch_results_storage["file_names"].append(file_name)
            batch_results_storage["ground_truths"].append(best_match)
            batch_results_storage["asr_results"].append(text)

            results.append(f"ğŸ“ **{file_name}**\n{text}\n")
            logger.info(f"ğŸ“ **{file_name}**\n{match_result}\n")

        except Exception as e:
            results.append(f"ğŸ“ **{file_name}**\nâŒ ì˜¤ë¥˜: {str(e)}\n")
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_name} - {e}")

            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì €ì¥
            batch_results_storage["file_names"].append(file_name)
            batch_results_storage["ground_truths"].append("")
            batch_results_storage["asr_results"].append(f"ERROR: {str(e)}")

    output = f"âœ… ì´ {total}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ\n\n" + "\n".join(results)
    return output


def generate_batch_csv_handler():
    """ë°°ì¹˜ í…ŒìŠ¤íŠ¸ CSV ë¦¬í¬íŠ¸ ìƒì„± í•¸ë“¤ëŸ¬"""
    if not batch_results_storage["file_names"]:
        return None, "âš ï¸ ìƒì„±í•  ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°°ì¹˜ ë³€í™˜ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."

    # CSV ìƒì„±
    csv_path = generate_batch_csv_report(
        file_names=batch_results_storage["file_names"],
        ground_truths=batch_results_storage["ground_truths"],
        asr_results=batch_results_storage["asr_results"],
        matcher=matcher
    )

    if csv_path and os.path.exists(csv_path):
        count = len(batch_results_storage["file_names"])
        return csv_path, f"âœ… CSV ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\n\nğŸ“Š ì´ {count}ê°œ íŒŒì¼ ì²˜ë¦¬\nğŸ“ íŒŒì¼: {csv_path}"
    else:
        return None, "âŒ CSV ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"


# ====================
# UI ìƒì„±
# ====================
def create_ui():
    """Gradio UI ìƒì„±"""

    css = """
    /* ì¶œë ¥ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ - ì±„íŒ… ìŠ¤íƒ€ì¼ */
    .output-box textarea {
        font-family: 'Courier New', monospace;
        font-size: 14px;
        line-height: 1.8;
        overflow-y: auto !important;
        max-height: 600px;
        white-space: pre-wrap;
        word-wrap: break-word;
    }
    
    /* ìŠ¤í¬ë¡¤ë°” ìŠ¤íƒ€ì¼ */
    .output-box textarea::-webkit-scrollbar {
        width: 12px;
    }
    
    .output-box textarea::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 10px;
    }
    
    .output-box textarea::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 10px;
    }
    
    .output-box textarea::-webkit-scrollbar-thumb:hover {
        background: #555;
    }
    """

    with gr.Blocks(
        title="ì•ˆì „ê´€ë¦¬ ì†”ë£¨ì…˜ ìŒì„±ê°ì§€ AI í…ŒìŠ¤íŠ¸",
        css=css,
    ) as demo:
        gr.Markdown("""
        # ğŸ™ï¸ ì•ˆì „ê´€ë¦¬ ì†”ë£¨ì…˜ ìŒì„±ê°ì§€ AI í…ŒìŠ¤íŠ¸

        RK3588 NPU ìµœì í™” ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œ (v4 - CSV ë¦¬í¬íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)
        """)

        with gr.Tabs():
            # íƒ­ 1: VAD ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹
            with gr.Tab("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ (VAD)"):
                gr.Markdown("""
                ### VAD ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œ (v5 - VAD ìë™ ê°ì§€)

                ğŸ”§ **v5 ì‹ ê·œ ê¸°ëŠ¥**:
                - âœ… **VAD (Voice Activity Detection)** - ìŒì„± ìë™ ê°ì§€
                - âœ… **ê°„í¸í•œ ì‚¬ìš©** - ë§ˆì´í¬ ë²„íŠ¼ë§Œ í´ë¦­í•˜ë©´ ìë™ ì¸ì‹ ì‹œì‘
                - âœ… **ìë™ ASR-STT** - ìŒì„± ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ ì¸ì‹
                - âœ… **ì‘ê¸‰ ìƒí™© ì‹¤ì‹œê°„ ê°ì§€** - í‚¤ì›Œë“œ ê¸°ë°˜ ì¦‰ì‹œ ì•Œë¦¼
                - âœ… ì„¸ì…˜ë³„ CSV ë¦¬í¬íŠ¸ ìë™ ìƒì„±
                """)

                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("""
                        ### ğŸ¤ ë§ˆì´í¬ ì…ë ¥
                        
                        **ì‚¬ìš© ë°©ë²•:**
                        1. ì•„ë˜ ë§ˆì´í¬ ë²„íŠ¼(ğŸ¤) í´ë¦­
                        2. ë§í•˜ê¸° ì‹œì‘ - ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤
                        3. ì¹¨ë¬µí•˜ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ìŒì„± ëŒ€ê¸°
                        4. ì¢…ë£Œí•˜ë ¤ë©´ "ìŒì„±ì¸ì‹ ì¢…ë£Œ" ë²„íŠ¼ í´ë¦­
                        """)
                        
                        audio_stream_vad = gr.Audio(
                            sources=["microphone"],
                            type="numpy",
                            streaming=True,
                            label="ğŸ™ï¸ ë§ˆì´í¬ (í´ë¦­í•˜ì—¬ ì‹œì‘)",
                        )

                        language_stream_vad = gr.Dropdown(
                            choices=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì¤‘êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ê´‘ë™ì–´"],
                            value="ìë™ ê°ì§€",
                            label="ğŸŒ ì–¸ì–´ ì„ íƒ",
                        )

                        ground_truth_input_vad = gr.Textbox(
                            label="ğŸ“ ì •ë‹µ (Ground Truth) ì…ë ¥ (ì„ íƒì‚¬í•­)",
                            placeholder="ì˜ˆ: ë„ì™€ì¤˜ ì‚¬ëŒì´ ì“°ëŸ¬ì¡Œì–´",
                            lines=2
                        )

                        with gr.Row():
                            stop_vad_btn = gr.Button("â¹ï¸ ìŒì„±ì¸ì‹ ì¢…ë£Œ", variant="stop", size="lg")
                            reset_vad_btn = gr.Button("ğŸ”„ ìƒˆë¡œ ì‹œì‘", variant="secondary", size="sm")

                    with gr.Column(scale=1):
                        output_stream_vad = gr.Textbox(
                            label="ğŸ“„ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ê²°ê³¼ (ì±„íŒ… ìŠ¤íƒ€ì¼)",
                            lines=20,
                            max_lines=30,
                            elem_classes="output-box",
                            autoscroll=True,
                            show_copy_button=True,
                        )

                gr.Markdown("### ğŸ“Š ì„¸ì…˜ ê´€ë¦¬ ë° CSV ë¦¬í¬íŠ¸")

                with gr.Row():
                    generate_csv_btn_vad = gr.Button("ğŸ“¥ CSV ë¦¬í¬íŠ¸ ìƒì„±", variant="secondary", size="lg")
                    clear_sessions_btn_vad = gr.Button("ğŸ—‘ï¸ ì„¸ì…˜ ì´ˆê¸°í™”", variant="stop", size="sm")

                csv_output_file_vad = gr.File(label="ğŸ“ ìƒì„±ëœ CSV íŒŒì¼")
                csv_status_vad = gr.Textbox(label="ğŸ“Š CSV ìƒì„± ìƒíƒœ", lines=3)

                gr.Markdown("""
                #### ğŸ’¡ ê°„í¸í•œ ì‚¬ìš©ë²•
                1. ğŸ¤ **ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­** â†’ ë…¹ìŒ ì‹œì‘ (ë¸Œë¼ìš°ì €ê°€ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­)
                2. ğŸ—£ï¸ **ë§í•˜ê¸°** â†’ VADê°€ ìë™ ê°ì§€í•˜ì—¬ ì‹¤ì‹œê°„ ì¸ì‹
                3. ğŸ”‡ **ì ì‹œ ì¹¨ë¬µ** â†’ ìë™ìœ¼ë¡œ êµ¬ê°„ êµ¬ë¶„ ë° ê²°ê³¼ í‘œì‹œ
                4. ğŸ”„ **ê³„ì† ë§í•˜ê¸°** â†’ ì—¬ëŸ¬ êµ¬ê°„ ì—°ì† ì¸ì‹ ê°€ëŠ¥
                5. â¹ï¸ **"ìŒì„±ì¸ì‹ ì¢…ë£Œ"** â†’ ì„¸ì…˜ ì¢…ë£Œ ë° ì „ì²´ ê²°ê³¼ í™•ì¸
                6. ğŸ“ **(ì„ íƒ) ì •ë‹µ ì…ë ¥** â†’ CSV ë¦¬í¬íŠ¸ ìƒì„± ì‹œ í™œìš©
                
                #### âš¡ v5 íŠ¹ì§• (VAD ê¸°ë°˜)
                - ğŸ¯ **ì™„ì „ ìë™** - ë§ˆì´í¬ë§Œ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ìŒì„± ê°ì§€ ì‹œì‘
                - â±ï¸ **ì‹¤ì‹œê°„ í‘œì‹œ** - ìŒì„± êµ¬ê°„ë§ˆë‹¤ ì¦‰ì‹œ ê²°ê³¼ í™”ë©´ í‘œì‹œ
                - ğŸš¨ **ì‘ê¸‰ ì¦‰ì‹œ ì•Œë¦¼** - ì‘ê¸‰ í‚¤ì›Œë“œ ê°ì§€ ì‹œ API ìë™ í˜¸ì¶œ
                - ğŸ“Š **êµ¬ê°„ë³„ ì €ì¥** - ê° ìŒì„± êµ¬ê°„ ê°œë³„ ì €ì¥ ë° ê´€ë¦¬
                - ğŸ”‡ **ìë™ êµ¬ê°„ ë¶„ë¦¬** - ì¹¨ë¬µ 1.5ì´ˆ ê°ì§€ë¡œ ìë™ êµ¬ê°„ êµ¬ë¶„
                
                #### âš™ï¸ ì¡°ì • ê°€ëŠ¥í•œ ì„¤ì •
                - **ì—ë„ˆì§€ ì„ê³„ê°’**: 0.01 (ë‚®ì„ìˆ˜ë¡ ì‘ì€ ì†Œë¦¬ë„ ê°ì§€)
                - **ì¹¨ë¬µ íŒë‹¨**: 1.5ì´ˆ (ì¹¨ë¬µìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ì‹œê°„)
                - **ìµœì†Œ ìŒì„± ê¸¸ì´**: 0.5ì´ˆ (ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ë¬´ì‹œ)
                """)

                # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
                audio_stream_vad.stream(
                    fn=process_vad_audio_stream,
                    inputs=[audio_stream_vad, language_stream_vad],
                    outputs=output_stream_vad,
                )

                stop_vad_btn.click(
                    fn=stop_vad_session_handler,
                    inputs=[ground_truth_input_vad],
                    outputs=[output_stream_vad, ground_truth_input_vad],
                )
                
                reset_vad_btn.click(
                    fn=reset_vad_session_handler,
                    inputs=None,
                    outputs=[audio_stream_vad, output_stream_vad, ground_truth_input_vad],
                )

                generate_csv_btn_vad.click(
                    fn=generate_mic_csv_handler,
                    inputs=None,
                    outputs=[csv_output_file_vad, csv_status_vad]
                )

                clear_sessions_btn_vad.click(
                    fn=clear_mic_sessions_handler,
                    inputs=None,
                    outputs=csv_status_vad
                )

            # íƒ­ 2: ê¸°ì¡´ ë°©ì‹ (ë ˆê±°ì‹œ)
            with gr.Tab("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ (ê¸°ì¡´ ë°©ì‹)"):
                gr.Markdown("""
                ### ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìŒì„±ì¸ì‹ (v4 - ê¸°ì¡´ ë°©ì‹)

                ğŸ”§ **v4 ê¸°ëŠ¥**:
                - âœ… ë§ˆì´í¬ ì„¸ì…˜ ê²°ê³¼ ìë™ ëˆ„ì  ì €ì¥
                - âœ… ì„¸ì…˜ë³„ CSV ë¦¬í¬íŠ¸ ìë™ ìƒì„±
                - âœ… ì„¸ì…˜ ê²°ê³¼ ì´ˆê¸°í™” ê¸°ëŠ¥
                - âœ… ì •ë‹µ(Ground Truth) ì…ë ¥ ì§€ì›
                """)

                with gr.Row():
                    with gr.Column(scale=1):
                        audio_stream = gr.Audio(
                            sources=["microphone"],
                            type="numpy",
                            streaming=True,
                            label="ğŸ™ï¸ ë§ˆì´í¬ (ì‹¤ì‹œê°„ ìˆ˜ì§‘)",
                        )

                        language_stream = gr.Dropdown(
                            choices=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì¤‘êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ê´‘ë™ì–´"],
                            value="ìë™ ê°ì§€",
                            label="ğŸŒ ì–¸ì–´ ì„ íƒ",
                        )

                        ground_truth_input = gr.Textbox(
                            label="ğŸ“ ì •ë‹µ (Ground Truth) ì…ë ¥ (ì„ íƒì‚¬í•­)",
                            placeholder="ì˜ˆ: íšŒì˜ëŠ” ì˜¤í›„ ì„¸ ì‹œì— ì‹œì‘í•´ ì•Œë¦¼ ì„¤ì •í•´ ì¤˜",
                            lines=2
                        )

                        with gr.Row():
                            start_btn = gr.Button("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘", variant="primary", size="lg")
                            stop_btn = gr.Button("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ", variant="stop", size="lg")

                    with gr.Column(scale=1):
                        output_stream = gr.Textbox(
                            label="ğŸ“„ ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ê²°ê³¼",
                            lines=15,
                            elem_classes="output-box",
                            #show_copy_button=True,
                        )

                gr.Markdown("### ğŸ“Š ì„¸ì…˜ ê´€ë¦¬ ë° CSV ë¦¬í¬íŠ¸")

                with gr.Row():
                    generate_csv_btn = gr.Button("ğŸ“¥ CSV ë¦¬í¬íŠ¸ ìƒì„±", variant="secondary", size="lg")
                    clear_sessions_btn = gr.Button("ğŸ—‘ï¸ ì„¸ì…˜ ì´ˆê¸°í™”", variant="stop", size="sm")

                csv_output_file = gr.File(label="ğŸ“ ìƒì„±ëœ CSV íŒŒì¼")
                csv_status = gr.Textbox(label="ğŸ“Š CSV ìƒì„± ìƒíƒœ", lines=3)

                gr.Markdown("""
                #### ğŸ’¡ ì‚¬ìš© ë°©ë²•
                1. ğŸŸ¡ **"ë…¹ìŒ ì‹œì‘" ë²„íŠ¼ í´ë¦­** â†’ ì¤€ë¹„ ì™„ë£Œ
                2. ğŸ“ **(ì„ íƒ) ì •ë‹µ(Ground Truth) ì…ë ¥** â†’ CSV ë¦¬í¬íŠ¸ì— ì‚¬ìš©
                3. ğŸ¤ **ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­** â†’ ìë™ ë…¹ìŒ ì‹œì‘
                4. ğŸ—£ï¸ **ë§í•˜ê¸°** â†’ 2ì´ˆë§ˆë‹¤ ì‹¤ì‹œê°„ ì¸ì‹
                5. â¹ï¸ **"ë…¹ìŒ ì¢…ë£Œ" ë²„íŠ¼ í´ë¦­** â†’ ê²°ê³¼ ì €ì¥ ë° ìµœì¢… ê²°ê³¼ í‘œì‹œ
                6. ğŸ”„ **ë°˜ë³µ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥** â†’ ì—¬ëŸ¬ ì„¸ì…˜ ëˆ„ì  ì €ì¥
                7. ğŸ“¥ **"CSV ë¦¬í¬íŠ¸ ìƒì„±" í´ë¦­** â†’ ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
                8. ğŸ—‘ï¸ **"ì„¸ì…˜ ì´ˆê¸°í™”" í´ë¦­** â†’ ì €ì¥ëœ ëª¨ë“  ì„¸ì…˜ ê²°ê³¼ ì‚­ì œ

                #### âš¡ v4 íŠ¹ì§•
                - âœ… ì„¸ì…˜ë³„ ê²°ê³¼ ìë™ ëˆ„ì  (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
                - âœ… CER(Character Error Rate) ìë™ ê³„ì‚°
                - âœ… CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì§€ì›
                - âœ… ì •ë‹µ ì…ë ¥ìœ¼ë¡œ ì •í™•í•œ í‰ê°€ ê°€ëŠ¥
                """)

                start_btn.click(
                    fn=start_recording_handler,
                    inputs=None,
                    outputs=[start_btn, stop_btn, audio_stream, output_stream],
                )

                stop_btn.click(
                    fn=stop_recording_handler,
                    inputs=[ground_truth_input],
                    outputs=[start_btn, stop_btn, output_stream, ground_truth_input],
                )

                audio_stream.stream(
                    fn=collect_and_process_audio,
                    inputs=[audio_stream, language_stream],
                    outputs=output_stream,
                )

                generate_csv_btn.click(
                    fn=generate_mic_csv_handler,
                    inputs=None,
                    outputs=[csv_output_file, csv_status]
                )

                clear_sessions_btn.click(
                    fn=clear_mic_sessions_handler,
                    inputs=None,
                    outputs=csv_status
                )

            # íƒ­ 2: íŒŒì¼ ì—…ë¡œë“œ
            with gr.Tab("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ"):
                gr.Markdown("### ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ\nWAV, MP3, FLAC, M4A ë“± ì§€ì›")

                with gr.Row():
                    with gr.Column(scale=1):
                        audio_file = gr.File(
                            label="ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
                            file_types=["audio"],
                        )

                        language_file = gr.Dropdown(
                            choices=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì¤‘êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ê´‘ë™ì–´"],
                            value="ìë™ ê°ì§€",
                            label="ğŸŒ ì–¸ì–´ ì„ íƒ",
                        )

                        transcribe_btn = gr.Button("ğŸš€ ë³€í™˜ ì‹œì‘", variant="primary", size="lg")
                        clear_btn = gr.Button("ğŸ—‘ï¸ ì´ˆê¸°í™”", size="sm")

                    with gr.Column(scale=1):
                        output_file = gr.Textbox(
                            label="ğŸ“„ ë³€í™˜ ê²°ê³¼",
                            lines=15,
                            elem_classes="output-box",
                            #show_copy_button=True,
                        )

                transcribe_btn.click(
                    fn=transcribe_file,
                    inputs=[audio_file, language_file],
                    outputs=output_file,
                )

                clear_btn.click(
                    fn=lambda: (None, ""),
                    outputs=[audio_file, output_file],
                )

            # íƒ­ 3: ë°°ì¹˜ ì²˜ë¦¬ (CSV ìƒì„± ê¸°ëŠ¥ í†µí•©)
            with gr.Tab("ğŸ“¦ ë°°ì¹˜ ë³€í™˜"):
                gr.Markdown("""
                ### ğŸ“¥ ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬ ë° CSV ë¦¬í¬íŠ¸ ìƒì„±

                ğŸ”§ **v4 ì‹ ê·œ ê¸°ëŠ¥**:
                - âœ… ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ìë™ ì €ì¥
                - âœ… CSV ë¦¬í¬íŠ¸ ìë™ ìƒì„± (CER í¬í•¨)
                """)

                with gr.Row():
                    with gr.Column():
                        batch_files = gr.File(
                            file_count="multiple",
                            label="ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                            file_types=["audio"],
                        )

                        batch_language = gr.Dropdown(
                            choices=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì¤‘êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ê´‘ë™ì–´"],
                            value="ìë™ ê°ì§€",
                            label="ğŸŒ ì–¸ì–´ ì„ íƒ",
                        )

                        batch_btn = gr.Button("ğŸš€ ì¼ê´„ ë³€í™˜", variant="primary", size="lg")

                    with gr.Column():
                        batch_output = gr.Textbox(
                            label="ğŸ“„ ì¼ê´„ ë³€í™˜ ê²°ê³¼",
                            lines=20,
                            #show_copy_button=True,
                        )

                gr.Markdown("### ğŸ“Š ë°°ì¹˜ í…ŒìŠ¤íŠ¸ CSV ë¦¬í¬íŠ¸")

                generate_batch_csv_btn = gr.Button("ğŸ“¥ CSV ë¦¬í¬íŠ¸ ìƒì„±", variant="secondary", size="lg")

                batch_csv_output_file = gr.File(label="ğŸ“ ìƒì„±ëœ CSV íŒŒì¼")
                batch_csv_status = gr.Textbox(label="ğŸ“Š CSV ìƒì„± ìƒíƒœ", lines=3)

                batch_btn.click(
                    fn=batch_transcribe,
                    inputs=[batch_files, batch_language],
                    outputs=batch_output,
                )

                generate_batch_csv_btn.click(
                    fn=generate_batch_csv_handler,
                    inputs=None,
                    outputs=[batch_csv_output_file, batch_csv_status]
                )

        gr.Markdown("""
        ---
        <div style="text-align: center; color: #666; padding: 20px;">
            Powered by Sherpa-ONNX + Gradio | RK3588 NPU | v4 (CSV ë¦¬í¬íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)
        </div>
        """)

    return demo


# ====================
# ë©”ì¸ ì‹¤í–‰
# ====================
if __name__ == "__main__":
    logger.info("\n" + "=" * 60)
    logger.info("ğŸš€ Sherpa-ONNX Sense-Voice ìŒì„±ì¸ì‹ UI ì‹œì‘")
    logger.info("ğŸ–¥ï¸ RK3588 NPU ìµœì í™” (v4 - CSV ë¦¬í¬íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)")
    logger.info("=" * 60 + "\n")

    try:
        load_model()
    except Exception as e:
        logger.error(f"\nâŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}", exc_info=True)
        logger.error("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        exit(1)

    demo = create_ui()
    demo.queue()

    logger.info("\n" + "=" * 60)
    logger.info("ğŸŒ ì›¹ ì„œë²„ ì‹œì‘...")
    logger.info("ğŸ’¡ RK3588 NPU 4ì½”ì–´ ì‚¬ìš©:")
    logger.info("   taskset 0x0F python asr_test_improved.py")
    logger.info("=" * 60)

    try:
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            show_error=True,
            inbrowser=False,
            ssl_keyfile="server.key",
            ssl_certfile="server.crt",
        )
    except Exception as e:
        # SSL ê²€ì¦ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë¨
        if "CERTIFICATE_VERIFY_FAILED" in str(e) or "SSL" in str(e):
            logger.warning(f"âš ï¸ SSL ê²€ì¦ ê²½ê³  (ë¬´ì‹œë¨): {e}")
            logger.info("âœ… ì„œë²„ëŠ” ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•´ì£¼ì„¸ìš”.")
            # ì„œë²„ê°€ ì´ë¯¸ ì‹œì‘ë˜ì—ˆìœ¼ë¯€ë¡œ ë¬´í•œ ëŒ€ê¸°
            import time
            while True:
                time.sleep(1)
        else:
            raise
